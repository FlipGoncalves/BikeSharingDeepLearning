{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"./StationsDatasets/trainingMax.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "testing_data = pd.read_csv(\"./StationsDatasets/testingMax.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "validating_data = pd.read_csv(\"./StationsDatasets/validationMax.csv\").drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"StationEnd\", \"Count\", \"Count1\", \"Count1week\", \"Count2week\", \"Count3week\", \"Count4week\", \"Temp\", \"ATemp\", \"Humidity\", \"Hour\", \"WeatherSituation\"]\n",
    "\n",
    "training_data = training_data[[col for col in training_data.columns if col in cols]]\n",
    "testing_data = testing_data[[col for col in testing_data.columns if col in cols]]\n",
    "validating_data = validating_data[[col for col in validating_data.columns if col in cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = training_data.drop(columns=[\"Count\"])\n",
    "trainY = training_data[\"Count\"]\n",
    "\n",
    "testX = testing_data.drop(columns=[\"Count\"])\n",
    "testY = testing_data[\"Count\"]\n",
    "\n",
    "valX = validating_data.drop(columns=[\"Count\"])\n",
    "valY = validating_data[\"Count\"]\n",
    "\n",
    "trainX = np.reshape(trainX.values, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX.values, (testX.shape[0], 1, testX.shape[1]))\n",
    "valX = np.reshape(valX.values, (valX.shape[0], 1, valX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 16:10:56.445158: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-06 16:10:56.446320: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-06 16:10:56.447089: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-06 16:10:56.602917: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-06 16:10:56.603783: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-06 16:10:56.604511: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-06 16:10:56.901872: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-06 16:10:56.902944: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-06 16:10:56.903610: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150406/150406 - 123s - loss: 33.8270 - 123s/epoch - 815us/step\n",
      "Epoch 2/40\n",
      "150406/150406 - 122s - loss: 27.7012 - 122s/epoch - 811us/step\n",
      "Epoch 3/40\n",
      "150406/150406 - 121s - loss: 27.9817 - 121s/epoch - 806us/step\n",
      "Epoch 4/40\n",
      "150406/150406 - 122s - loss: 27.9000 - 122s/epoch - 810us/step\n",
      "Epoch 5/40\n",
      "150406/150406 - 122s - loss: 27.1267 - 122s/epoch - 812us/step\n",
      "Epoch 6/40\n",
      "150406/150406 - 122s - loss: 26.9775 - 122s/epoch - 814us/step\n",
      "Epoch 7/40\n",
      "150406/150406 - 122s - loss: 26.8503 - 122s/epoch - 809us/step\n",
      "Epoch 8/40\n",
      "150406/150406 - 122s - loss: 26.8149 - 122s/epoch - 811us/step\n",
      "Epoch 9/40\n",
      "150406/150406 - 122s - loss: 26.6727 - 122s/epoch - 810us/step\n",
      "Epoch 10/40\n",
      "150406/150406 - 119s - loss: 26.5110 - 119s/epoch - 793us/step\n",
      "Epoch 11/40\n",
      "150406/150406 - 122s - loss: 26.4803 - 122s/epoch - 810us/step\n",
      "Epoch 12/40\n",
      "150406/150406 - 122s - loss: 26.4563 - 122s/epoch - 811us/step\n",
      "Epoch 13/40\n",
      "150406/150406 - 121s - loss: 26.3909 - 121s/epoch - 806us/step\n",
      "Epoch 14/40\n",
      "150406/150406 - 122s - loss: 26.4364 - 122s/epoch - 810us/step\n",
      "Epoch 15/40\n",
      "150406/150406 - 121s - loss: 26.3254 - 121s/epoch - 806us/step\n",
      "Epoch 16/40\n",
      "150406/150406 - 122s - loss: 26.5974 - 122s/epoch - 811us/step\n",
      "Epoch 17/40\n",
      "150406/150406 - 121s - loss: 26.6486 - 121s/epoch - 807us/step\n",
      "Epoch 18/40\n",
      "150406/150406 - 121s - loss: 26.5427 - 121s/epoch - 807us/step\n",
      "Epoch 19/40\n",
      "150406/150406 - 121s - loss: 26.4431 - 121s/epoch - 806us/step\n",
      "Epoch 20/40\n",
      "150406/150406 - 121s - loss: 26.4970 - 121s/epoch - 803us/step\n",
      "Epoch 21/40\n",
      "150406/150406 - 121s - loss: 26.4177 - 121s/epoch - 805us/step\n",
      "Epoch 22/40\n",
      "150406/150406 - 122s - loss: 26.5047 - 122s/epoch - 812us/step\n",
      "Epoch 23/40\n",
      "150406/150406 - 121s - loss: 26.4931 - 121s/epoch - 801us/step\n",
      "Epoch 24/40\n",
      "150406/150406 - 121s - loss: 26.5141 - 121s/epoch - 804us/step\n",
      "Epoch 25/40\n",
      "150406/150406 - 121s - loss: 26.5127 - 121s/epoch - 803us/step\n",
      "Epoch 26/40\n",
      "150406/150406 - 121s - loss: 26.4225 - 121s/epoch - 802us/step\n",
      "Epoch 27/40\n",
      "150406/150406 - 122s - loss: 26.3462 - 122s/epoch - 811us/step\n",
      "Epoch 28/40\n",
      "150406/150406 - 122s - loss: 26.3836 - 122s/epoch - 808us/step\n",
      "Epoch 29/40\n",
      "150406/150406 - 122s - loss: 26.5020 - 122s/epoch - 809us/step\n",
      "Epoch 30/40\n",
      "150406/150406 - 122s - loss: 26.4475 - 122s/epoch - 810us/step\n",
      "Epoch 31/40\n",
      "150406/150406 - 122s - loss: 26.4676 - 122s/epoch - 809us/step\n",
      "Epoch 32/40\n",
      "150406/150406 - 120s - loss: 26.4654 - 120s/epoch - 799us/step\n",
      "Epoch 33/40\n",
      "150406/150406 - 121s - loss: 26.5012 - 121s/epoch - 802us/step\n",
      "Epoch 34/40\n",
      "150406/150406 - 121s - loss: 26.5077 - 121s/epoch - 804us/step\n",
      "Epoch 35/40\n",
      "150406/150406 - 120s - loss: 26.5068 - 120s/epoch - 799us/step\n",
      "Epoch 36/40\n",
      "150406/150406 - 121s - loss: 26.5449 - 121s/epoch - 806us/step\n",
      "Epoch 37/40\n",
      "150406/150406 - 121s - loss: 26.4254 - 121s/epoch - 804us/step\n",
      "Epoch 38/40\n",
      "150406/150406 - 121s - loss: 26.4379 - 121s/epoch - 805us/step\n",
      "Epoch 39/40\n",
      "150406/150406 - 122s - loss: 26.4837 - 122s/epoch - 814us/step\n",
      "Epoch 40/40\n",
      "150406/150406 - 122s - loss: 26.4924 - 122s/epoch - 813us/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1,training_data.shape[1]-1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=40, batch_size=1, verbose=2)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(pd.concat([training_data, testing_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4701/4701 [==============================] - 3s 545us/step\n",
      "Train Score: 5.19 RMSE\n",
      "1176/1176 [==============================] - 1s 586us/step - loss: 26.9315\n",
      "Train Accuracy: 26.931499481201172\n"
     ]
    }
   ],
   "source": [
    "trainPredict = model.predict(trainX)\n",
    "\n",
    "trainScore = np.sqrt(mean_squared_error(trainY[:], trainPredict[:]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "results = model.evaluate(trainX, trainY, batch_size=128)\n",
    "print(\"Train Accuracy:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1661/1661 [==============================] - 1s 550us/step\n",
      "Test Score: 5.22 RMSE\n",
      "416/416 [==============================] - 0s 618us/step - loss: 27.2241\n",
      "Test Accuracy: 27.224096298217773\n"
     ]
    }
   ],
   "source": [
    "testPredict = model.predict(testX)\n",
    "\n",
    "testScore = np.sqrt(mean_squared_error(testY[:], testPredict[:]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "results = model.evaluate(testX, testY, batch_size=128)\n",
    "print(\"Test Accuracy:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710/1710 [==============================] - 1s 537us/step\n",
      "Validation Score: 5.12 RMSE\n",
      "428/428 [==============================] - 0s 574us/step - loss: 26.1960\n",
      "Validation Accuracy: 26.19596290588379\n"
     ]
    }
   ],
   "source": [
    "valPredict = model.predict(valX)\n",
    "\n",
    "valScore = np.sqrt(mean_squared_error(valY[:], valPredict[:]))\n",
    "print('Validation Score: %.2f RMSE' % (valScore))\n",
    "results = model.evaluate(valX, valY, batch_size=128)\n",
    "print(\"Validation Accuracy:\", results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With different cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_min = pd.read_csv(\"./StationsDatasets/trainingMin.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "testing_data_min = pd.read_csv(\"./StationsDatasets/testingMin.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "validating_data_min = pd.read_csv(\"./StationsDatasets/validationMin.csv\").drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"StationEnd\", \"Count\", \"Count1\", \"Count1week\", \"Count2week\", \"Count3week\", \"Count4week\", \"Temp\", \"ATemp\", \"Humidity\", \"Hour\", \"WeatherSituation\"]\n",
    "\n",
    "training_data_min = training_data_min[[col for col in training_data_min.columns if col in cols]]\n",
    "testing_data_min = testing_data_min[[col for col in testing_data_min.columns if col in cols]]\n",
    "validating_data_min = validating_data_min[[col for col in validating_data_min.columns if col in cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4125/4125 [==============================] - 2s 535us/step\n",
      "Validation Score: 3.09 RMSE\n",
      "1032/1032 [==============================] - 1s 579us/step - loss: 9.5331\n",
      "Validation Accuracy: 9.533097267150879\n"
     ]
    }
   ],
   "source": [
    "valX = training_data_min.drop(columns=[\"Count\"])\n",
    "valY = training_data_min[\"Count\"]\n",
    "\n",
    "valX = np.reshape(valX.values, (valX.shape[0], 1, valX.shape[1]))\n",
    "\n",
    "valPredict = model.predict(valX)\n",
    "\n",
    "valScore = np.sqrt(mean_squared_error(valY[:], valPredict[:]))\n",
    "print('Validation Score: %.2f RMSE' % (valScore))\n",
    "results = model.evaluate(valX, valY, batch_size=128)\n",
    "print(\"Validation Accuracy:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862/862 [==============================] - 0s 545us/step\n",
      "Validation Score: 3.05 RMSE\n",
      "216/216 [==============================] - 0s 571us/step - loss: 9.3079\n",
      "Validation Accuracy: 9.307868957519531\n"
     ]
    }
   ],
   "source": [
    "valX = testing_data_min.drop(columns=[\"Count\"])\n",
    "valY = testing_data_min[\"Count\"]\n",
    "\n",
    "valX = np.reshape(valX.values, (valX.shape[0], 1, valX.shape[1]))\n",
    "\n",
    "valPredict = model.predict(valX)\n",
    "\n",
    "valScore = np.sqrt(mean_squared_error(valY[:], valPredict[:]))\n",
    "print('Validation Score: %.2f RMSE' % (valScore))\n",
    "results = model.evaluate(valX, valY, batch_size=128)\n",
    "print(\"Validation Accuracy:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1282/1282 [==============================] - 1s 528us/step\n",
      "Validation Score: 3.05 RMSE\n",
      "321/321 [==============================] - 0s 541us/step - loss: 9.3108\n",
      "Validation Accuracy: 9.310832023620605\n"
     ]
    }
   ],
   "source": [
    "valX = validating_data_min.drop(columns=[\"Count\"])\n",
    "valY = validating_data_min[\"Count\"]\n",
    "\n",
    "valX = np.reshape(valX.values, (valX.shape[0], 1, valX.shape[1]))\n",
    "\n",
    "valPredict = model.predict(valX)\n",
    "\n",
    "valScore = np.sqrt(mean_squared_error(valY[:], valPredict[:]))\n",
    "print('Validation Score: %.2f RMSE' % (valScore))\n",
    "results = model.evaluate(valX, valY, batch_size=128)\n",
    "print(\"Validation Accuracy:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
