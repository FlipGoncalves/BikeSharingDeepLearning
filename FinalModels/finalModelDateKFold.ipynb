{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 11:55:02.914519: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-11 11:55:02.967243: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-11 11:55:02.968068: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-11 11:55:03.954547: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../DateDatasets/dataset.csv\").drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Count\", \"Count1\", \"Count1week\", \"Count2week\", \"Count3week\", \"Temp\", \"ATemp\", \"Hour\", \"Humidity\", \"WeatherSituation\"]\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 1\n",
    "verbose = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 11:57:35.789569: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 11:57:35.791336: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 11:57:35.792101: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-11 11:57:36.004620: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 11:57:36.006198: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 11:57:36.007274: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-11 11:57:36.339425: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 11:57:36.340746: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 11:57:36.341505: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183062/183062 - 161s - loss: 4.2050 - accuracy: 0.3339 - 161s/epoch - 877us/step\n",
      "Epoch 2/20\n",
      "183062/183062 - 157s - loss: 4.0495 - accuracy: 0.3341 - 157s/epoch - 859us/step\n",
      "Epoch 3/20\n",
      "183062/183062 - 157s - loss: 4.0193 - accuracy: 0.3341 - 157s/epoch - 856us/step\n",
      "Epoch 4/20\n",
      "183062/183062 - 150s - loss: 4.0091 - accuracy: 0.3341 - 150s/epoch - 817us/step\n",
      "Epoch 5/20\n",
      "183062/183062 - 157s - loss: 3.9982 - accuracy: 0.3341 - 157s/epoch - 858us/step\n",
      "Epoch 6/20\n",
      "183062/183062 - 154s - loss: 3.9862 - accuracy: 0.3340 - 154s/epoch - 844us/step\n",
      "Epoch 7/20\n",
      "183062/183062 - 153s - loss: 3.9649 - accuracy: 0.3338 - 153s/epoch - 835us/step\n",
      "Epoch 8/20\n",
      "183062/183062 - 153s - loss: 3.9544 - accuracy: 0.3337 - 153s/epoch - 837us/step\n",
      "Epoch 9/20\n",
      "183062/183062 - 152s - loss: 3.9432 - accuracy: 0.3336 - 152s/epoch - 831us/step\n",
      "Epoch 10/20\n",
      "183062/183062 - 152s - loss: 3.9331 - accuracy: 0.3337 - 152s/epoch - 833us/step\n",
      "Epoch 11/20\n",
      "183062/183062 - 153s - loss: 3.9315 - accuracy: 0.3337 - 153s/epoch - 835us/step\n",
      "Epoch 12/20\n",
      "183062/183062 - 153s - loss: 3.9244 - accuracy: 0.3337 - 153s/epoch - 838us/step\n",
      "Epoch 13/20\n",
      "183062/183062 - 156s - loss: 3.9174 - accuracy: 0.3338 - 156s/epoch - 851us/step\n",
      "Epoch 14/20\n",
      "183062/183062 - 156s - loss: 3.9138 - accuracy: 0.3337 - 156s/epoch - 854us/step\n",
      "Epoch 15/20\n",
      "183062/183062 - 153s - loss: 3.9114 - accuracy: 0.3338 - 153s/epoch - 836us/step\n",
      "Epoch 16/20\n",
      "183062/183062 - 152s - loss: 3.9074 - accuracy: 0.3338 - 152s/epoch - 831us/step\n",
      "Epoch 17/20\n",
      "183062/183062 - 153s - loss: 3.9057 - accuracy: 0.3338 - 153s/epoch - 834us/step\n",
      "Epoch 18/20\n",
      "183062/183062 - 153s - loss: 3.8945 - accuracy: 0.3337 - 153s/epoch - 833us/step\n",
      "Epoch 19/20\n",
      "183062/183062 - 154s - loss: 3.8850 - accuracy: 0.3338 - 154s/epoch - 839us/step\n",
      "Epoch 20/20\n",
      "183062/183062 - 154s - loss: 3.8867 - accuracy: 0.3339 - 154s/epoch - 839us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 12:48:57.760196: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 12:48:57.761454: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 12:48:57.762152: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "183062/183062 - 154s - loss: 3.8795 - accuracy: 0.3334 - 154s/epoch - 840us/step\n",
      "Epoch 2/20\n",
      "183062/183062 - 159s - loss: 3.8795 - accuracy: 0.3334 - 159s/epoch - 867us/step\n",
      "Epoch 3/20\n",
      "183062/183062 - 159s - loss: 3.8742 - accuracy: 0.3334 - 159s/epoch - 867us/step\n",
      "Epoch 4/20\n",
      "183062/183062 - 158s - loss: 3.8656 - accuracy: 0.3335 - 158s/epoch - 861us/step\n",
      "Epoch 5/20\n",
      "183062/183062 - 158s - loss: 3.8601 - accuracy: 0.3335 - 158s/epoch - 862us/step\n",
      "Epoch 6/20\n",
      "183062/183062 - 157s - loss: 3.8553 - accuracy: 0.3335 - 157s/epoch - 860us/step\n",
      "Epoch 7/20\n",
      "183062/183062 - 157s - loss: 3.8484 - accuracy: 0.3335 - 157s/epoch - 857us/step\n",
      "Epoch 8/20\n",
      "183062/183062 - 158s - loss: 3.8428 - accuracy: 0.3335 - 158s/epoch - 864us/step\n",
      "Epoch 9/20\n",
      "183062/183062 - 156s - loss: 3.8405 - accuracy: 0.3336 - 156s/epoch - 854us/step\n",
      "Epoch 10/20\n",
      "183062/183062 - 158s - loss: 3.8346 - accuracy: 0.3336 - 158s/epoch - 861us/step\n",
      "Epoch 11/20\n",
      "183062/183062 - 157s - loss: 3.8305 - accuracy: 0.3336 - 157s/epoch - 860us/step\n",
      "Epoch 12/20\n",
      "183062/183062 - 157s - loss: 3.8333 - accuracy: 0.3335 - 157s/epoch - 856us/step\n",
      "Epoch 13/20\n",
      "183062/183062 - 157s - loss: 3.8322 - accuracy: 0.3336 - 157s/epoch - 859us/step\n",
      "Epoch 14/20\n",
      "183062/183062 - 157s - loss: 3.8333 - accuracy: 0.3335 - 157s/epoch - 856us/step\n",
      "Epoch 15/20\n",
      "183062/183062 - 158s - loss: 3.8282 - accuracy: 0.3336 - 158s/epoch - 862us/step\n",
      "Epoch 16/20\n",
      "183062/183062 - 156s - loss: 3.8331 - accuracy: 0.3336 - 156s/epoch - 854us/step\n",
      "Epoch 17/20\n",
      "183062/183062 - 157s - loss: 3.8312 - accuracy: 0.3336 - 157s/epoch - 858us/step\n",
      "Epoch 18/20\n",
      "183062/183062 - 157s - loss: 3.8274 - accuracy: 0.3336 - 157s/epoch - 856us/step\n",
      "Epoch 19/20\n",
      "183062/183062 - 157s - loss: 3.8266 - accuracy: 0.3336 - 157s/epoch - 860us/step\n",
      "Epoch 20/20\n",
      "183062/183062 - 158s - loss: 3.8326 - accuracy: 0.3336 - 158s/epoch - 862us/step\n",
      "Epoch 1/20\n",
      "183062/183062 - 157s - loss: 3.8410 - accuracy: 0.3337 - 157s/epoch - 856us/step\n",
      "Epoch 2/20\n",
      "183062/183062 - 158s - loss: 3.8461 - accuracy: 0.3337 - 158s/epoch - 861us/step\n",
      "Epoch 3/20\n",
      "183062/183062 - 157s - loss: 3.8465 - accuracy: 0.3337 - 157s/epoch - 857us/step\n",
      "Epoch 4/20\n",
      "183062/183062 - 158s - loss: 3.8431 - accuracy: 0.3338 - 158s/epoch - 861us/step\n",
      "Epoch 5/20\n",
      "183062/183062 - 157s - loss: 3.8396 - accuracy: 0.3337 - 157s/epoch - 857us/step\n",
      "Epoch 6/20\n",
      "183062/183062 - 158s - loss: 3.8429 - accuracy: 0.3336 - 158s/epoch - 861us/step\n",
      "Epoch 7/20\n",
      "183062/183062 - 157s - loss: 3.8376 - accuracy: 0.3337 - 157s/epoch - 860us/step\n",
      "Epoch 8/20\n",
      "183062/183062 - 157s - loss: 3.8430 - accuracy: 0.3337 - 157s/epoch - 859us/step\n",
      "Epoch 9/20\n",
      "183062/183062 - 158s - loss: 3.8414 - accuracy: 0.3337 - 158s/epoch - 863us/step\n",
      "Epoch 10/20\n",
      "183062/183062 - 157s - loss: 3.8421 - accuracy: 0.3336 - 157s/epoch - 858us/step\n",
      "Epoch 11/20\n",
      "183062/183062 - 157s - loss: 3.8452 - accuracy: 0.3337 - 157s/epoch - 858us/step\n",
      "Epoch 12/20\n",
      "183062/183062 - 158s - loss: 3.8436 - accuracy: 0.3337 - 158s/epoch - 861us/step\n",
      "Epoch 13/20\n",
      "183062/183062 - 158s - loss: 3.8426 - accuracy: 0.3336 - 158s/epoch - 863us/step\n",
      "Epoch 14/20\n",
      "183062/183062 - 158s - loss: 3.8421 - accuracy: 0.3338 - 158s/epoch - 866us/step\n",
      "Epoch 15/20\n",
      "183062/183062 - 158s - loss: 3.8467 - accuracy: 0.3338 - 158s/epoch - 861us/step\n",
      "Epoch 16/20\n",
      "183062/183062 - 157s - loss: 3.8427 - accuracy: 0.3335 - 157s/epoch - 860us/step\n",
      "Epoch 17/20\n",
      "183062/183062 - 157s - loss: 3.8434 - accuracy: 0.3337 - 157s/epoch - 859us/step\n",
      "Epoch 18/20\n",
      "183062/183062 - 158s - loss: 3.8436 - accuracy: 0.3338 - 158s/epoch - 863us/step\n",
      "Epoch 19/20\n",
      "183062/183062 - 157s - loss: 3.8425 - accuracy: 0.3337 - 157s/epoch - 856us/step\n",
      "Epoch 20/20\n",
      "183062/183062 - 158s - loss: 3.8401 - accuracy: 0.3337 - 158s/epoch - 862us/step\n",
      "Epoch 1/20\n",
      "183063/183063 - 157s - loss: 3.8299 - accuracy: 0.3330 - 157s/epoch - 858us/step\n",
      "Epoch 2/20\n",
      "183063/183063 - 158s - loss: 3.8303 - accuracy: 0.3331 - 158s/epoch - 861us/step\n",
      "Epoch 3/20\n",
      "183063/183063 - 158s - loss: 3.8317 - accuracy: 0.3330 - 158s/epoch - 861us/step\n",
      "Epoch 4/20\n",
      "183063/183063 - 157s - loss: 3.8259 - accuracy: 0.3331 - 157s/epoch - 859us/step\n",
      "Epoch 5/20\n",
      "183063/183063 - 158s - loss: 3.8279 - accuracy: 0.3331 - 158s/epoch - 862us/step\n",
      "Epoch 6/20\n",
      "183063/183063 - 159s - loss: 3.8319 - accuracy: 0.3331 - 159s/epoch - 870us/step\n",
      "Epoch 7/20\n",
      "183063/183063 - 157s - loss: 3.8278 - accuracy: 0.3331 - 157s/epoch - 860us/step\n",
      "Epoch 8/20\n",
      "183063/183063 - 157s - loss: 3.8275 - accuracy: 0.3331 - 157s/epoch - 859us/step\n",
      "Epoch 9/20\n",
      "183063/183063 - 156s - loss: 3.8252 - accuracy: 0.3329 - 156s/epoch - 853us/step\n",
      "Epoch 10/20\n",
      "183063/183063 - 157s - loss: 3.8300 - accuracy: 0.3328 - 157s/epoch - 856us/step\n",
      "Epoch 11/20\n",
      "183063/183063 - 158s - loss: 3.8279 - accuracy: 0.3330 - 158s/epoch - 861us/step\n",
      "Epoch 12/20\n",
      "183063/183063 - 157s - loss: 3.8273 - accuracy: 0.3330 - 157s/epoch - 859us/step\n",
      "Epoch 13/20\n",
      "183063/183063 - 158s - loss: 3.8284 - accuracy: 0.3330 - 158s/epoch - 860us/step\n",
      "Epoch 14/20\n",
      "183063/183063 - 158s - loss: 3.8300 - accuracy: 0.3332 - 158s/epoch - 863us/step\n",
      "Epoch 15/20\n",
      "183063/183063 - 158s - loss: 3.8262 - accuracy: 0.3332 - 158s/epoch - 863us/step\n",
      "Epoch 16/20\n",
      "183063/183063 - 158s - loss: 3.8295 - accuracy: 0.3331 - 158s/epoch - 861us/step\n",
      "Epoch 17/20\n",
      "183063/183063 - 158s - loss: 3.8247 - accuracy: 0.3329 - 158s/epoch - 861us/step\n",
      "Epoch 18/20\n",
      "183063/183063 - 159s - loss: 3.8228 - accuracy: 0.3331 - 159s/epoch - 866us/step\n",
      "Epoch 19/20\n",
      "183063/183063 - 160s - loss: 3.8256 - accuracy: 0.3331 - 160s/epoch - 874us/step\n",
      "Epoch 20/20\n",
      "183063/183063 - 151s - loss: 3.8273 - accuracy: 0.3331 - 151s/epoch - 827us/step\n",
      "Epoch 1/20\n",
      "183063/183063 - 160s - loss: 3.8243 - accuracy: 0.3335 - 160s/epoch - 876us/step\n",
      "Epoch 2/20\n",
      "183063/183063 - 151s - loss: 3.8234 - accuracy: 0.3335 - 151s/epoch - 827us/step\n",
      "Epoch 3/20\n",
      "183063/183063 - 152s - loss: 3.8244 - accuracy: 0.3336 - 152s/epoch - 830us/step\n",
      "Epoch 4/20\n",
      "183063/183063 - 160s - loss: 3.8257 - accuracy: 0.3336 - 160s/epoch - 876us/step\n",
      "Epoch 5/20\n",
      "183063/183063 - 174s - loss: 3.8257 - accuracy: 0.3336 - 174s/epoch - 952us/step\n",
      "Epoch 6/20\n",
      "183063/183063 - 177s - loss: 3.8290 - accuracy: 0.3335 - 177s/epoch - 967us/step\n",
      "Epoch 7/20\n",
      "183063/183063 - 170s - loss: 3.8241 - accuracy: 0.3335 - 170s/epoch - 928us/step\n",
      "Epoch 8/20\n",
      "183063/183063 - 163s - loss: 3.8260 - accuracy: 0.3337 - 163s/epoch - 890us/step\n",
      "Epoch 9/20\n",
      "183063/183063 - 158s - loss: 3.8254 - accuracy: 0.3336 - 158s/epoch - 861us/step\n",
      "Epoch 10/20\n",
      "183063/183063 - 161s - loss: 3.8241 - accuracy: 0.3337 - 161s/epoch - 882us/step\n",
      "Epoch 11/20\n",
      "183063/183063 - 161s - loss: 3.8225 - accuracy: 0.3336 - 161s/epoch - 879us/step\n",
      "Epoch 12/20\n",
      "183063/183063 - 160s - loss: 3.8206 - accuracy: 0.3336 - 160s/epoch - 875us/step\n",
      "Epoch 13/20\n",
      "183063/183063 - 161s - loss: 3.8260 - accuracy: 0.3336 - 161s/epoch - 878us/step\n",
      "Epoch 14/20\n",
      "183063/183063 - 159s - loss: 3.8239 - accuracy: 0.3337 - 159s/epoch - 871us/step\n",
      "Epoch 15/20\n",
      "183063/183063 - 166s - loss: 3.8207 - accuracy: 0.3338 - 166s/epoch - 907us/step\n",
      "Epoch 16/20\n",
      "183063/183063 - 162s - loss: 3.8198 - accuracy: 0.3338 - 162s/epoch - 884us/step\n",
      "Epoch 17/20\n",
      "183063/183063 - 161s - loss: 3.8175 - accuracy: 0.3338 - 161s/epoch - 879us/step\n",
      "Epoch 18/20\n",
      "183063/183063 - 159s - loss: 3.8111 - accuracy: 0.3338 - 159s/epoch - 871us/step\n",
      "Epoch 19/20\n",
      "183063/183063 - 163s - loss: 3.8093 - accuracy: 0.3337 - 163s/epoch - 889us/step\n",
      "Epoch 20/20\n",
      "183063/183063 - 171s - loss: 3.8067 - accuracy: 0.3338 - 171s/epoch - 932us/step\n",
      "Epoch 1/20\n",
      "183063/183063 - 176s - loss: 3.8125 - accuracy: 0.3335 - 176s/epoch - 964us/step\n",
      "Epoch 2/20\n",
      "183063/183063 - 165s - loss: 3.8143 - accuracy: 0.3335 - 165s/epoch - 900us/step\n",
      "Epoch 3/20\n",
      "183063/183063 - 159s - loss: 3.8179 - accuracy: 0.3334 - 159s/epoch - 870us/step\n",
      "Epoch 4/20\n",
      "183063/183063 - 156s - loss: 3.8137 - accuracy: 0.3335 - 156s/epoch - 855us/step\n",
      "Epoch 5/20\n",
      "183063/183063 - 159s - loss: 3.8126 - accuracy: 0.3334 - 159s/epoch - 866us/step\n",
      "Epoch 6/20\n",
      "183063/183063 - 158s - loss: 3.8152 - accuracy: 0.3335 - 158s/epoch - 862us/step\n",
      "Epoch 7/20\n",
      "183063/183063 - 156s - loss: 3.8115 - accuracy: 0.3334 - 156s/epoch - 852us/step\n",
      "Epoch 8/20\n",
      "183063/183063 - 163s - loss: 3.8125 - accuracy: 0.3333 - 163s/epoch - 890us/step\n",
      "Epoch 9/20\n",
      "183063/183063 - 165s - loss: 3.8092 - accuracy: 0.3334 - 165s/epoch - 900us/step\n",
      "Epoch 10/20\n",
      "183063/183063 - 163s - loss: 3.8064 - accuracy: 0.3334 - 163s/epoch - 890us/step\n",
      "Epoch 11/20\n",
      "183063/183063 - 164s - loss: 3.8070 - accuracy: 0.3335 - 164s/epoch - 898us/step\n",
      "Epoch 12/20\n",
      "183063/183063 - 156s - loss: 3.8081 - accuracy: 0.3334 - 156s/epoch - 854us/step\n",
      "Epoch 13/20\n",
      "183063/183063 - 155s - loss: 3.8078 - accuracy: 0.3334 - 155s/epoch - 846us/step\n",
      "Epoch 14/20\n",
      "183063/183063 - 154s - loss: 3.8043 - accuracy: 0.3333 - 154s/epoch - 840us/step\n",
      "Epoch 15/20\n",
      "183063/183063 - 155s - loss: 3.8109 - accuracy: 0.3334 - 155s/epoch - 844us/step\n",
      "Epoch 16/20\n",
      "183063/183063 - 153s - loss: 3.8057 - accuracy: 0.3335 - 153s/epoch - 838us/step\n",
      "Epoch 17/20\n",
      "183063/183063 - 156s - loss: 3.8027 - accuracy: 0.3334 - 156s/epoch - 851us/step\n",
      "Epoch 18/20\n",
      "183063/183063 - 155s - loss: 3.8048 - accuracy: 0.3334 - 155s/epoch - 846us/step\n",
      "Epoch 19/20\n",
      "183063/183063 - 155s - loss: 3.8019 - accuracy: 0.3335 - 155s/epoch - 849us/step\n",
      "Epoch 20/20\n",
      "183063/183063 - 155s - loss: 3.8021 - accuracy: 0.3334 - 155s/epoch - 849us/step\n",
      "Epoch 1/20\n",
      "183063/183063 - 163s - loss: 3.7963 - accuracy: 0.3334 - 163s/epoch - 892us/step\n",
      "Epoch 2/20\n",
      "183063/183063 - 172s - loss: 3.7976 - accuracy: 0.3334 - 172s/epoch - 942us/step\n",
      "Epoch 3/20\n",
      "183063/183063 - 159s - loss: 3.7971 - accuracy: 0.3334 - 159s/epoch - 866us/step\n",
      "Epoch 4/20\n",
      "183063/183063 - 155s - loss: 3.7990 - accuracy: 0.3333 - 155s/epoch - 847us/step\n",
      "Epoch 5/20\n",
      "183063/183063 - 155s - loss: 3.7986 - accuracy: 0.3334 - 155s/epoch - 848us/step\n",
      "Epoch 6/20\n",
      "183063/183063 - 156s - loss: 3.7996 - accuracy: 0.3334 - 156s/epoch - 854us/step\n",
      "Epoch 7/20\n",
      "183063/183063 - 154s - loss: 3.8012 - accuracy: 0.3334 - 154s/epoch - 841us/step\n",
      "Epoch 8/20\n",
      "183063/183063 - 155s - loss: 3.7941 - accuracy: 0.3335 - 155s/epoch - 847us/step\n",
      "Epoch 9/20\n",
      "183063/183063 - 155s - loss: 3.7948 - accuracy: 0.3334 - 155s/epoch - 849us/step\n",
      "Epoch 10/20\n",
      "183063/183063 - 155s - loss: 3.7971 - accuracy: 0.3334 - 155s/epoch - 849us/step\n",
      "Epoch 11/20\n",
      "183063/183063 - 155s - loss: 3.7959 - accuracy: 0.3335 - 155s/epoch - 848us/step\n",
      "Epoch 12/20\n",
      "183063/183063 - 155s - loss: 3.7977 - accuracy: 0.3335 - 155s/epoch - 846us/step\n",
      "Epoch 13/20\n",
      "183063/183063 - 155s - loss: 3.7948 - accuracy: 0.3334 - 155s/epoch - 848us/step\n",
      "Epoch 14/20\n",
      "183063/183063 - 155s - loss: 3.7914 - accuracy: 0.3334 - 155s/epoch - 848us/step\n",
      "Epoch 15/20\n",
      "183063/183063 - 153s - loss: 3.7923 - accuracy: 0.3334 - 153s/epoch - 837us/step\n",
      "Epoch 16/20\n",
      "183063/183063 - 155s - loss: 3.7983 - accuracy: 0.3332 - 155s/epoch - 844us/step\n",
      "Epoch 17/20\n",
      "183063/183063 - 155s - loss: 3.7964 - accuracy: 0.3333 - 155s/epoch - 847us/step\n",
      "Epoch 18/20\n",
      "183063/183063 - 155s - loss: 3.7975 - accuracy: 0.3334 - 155s/epoch - 847us/step\n",
      "Epoch 19/20\n",
      "183063/183063 - 154s - loss: 3.7914 - accuracy: 0.3334 - 154s/epoch - 841us/step\n",
      "Epoch 20/20\n",
      "183063/183063 - 155s - loss: 3.7966 - accuracy: 0.3334 - 155s/epoch - 846us/step\n",
      "Epoch 1/20\n",
      "183063/183063 - 154s - loss: 3.8097 - accuracy: 0.3342 - 154s/epoch - 844us/step\n",
      "Epoch 2/20\n",
      "183063/183063 - 155s - loss: 3.8051 - accuracy: 0.3341 - 155s/epoch - 846us/step\n",
      "Epoch 3/20\n",
      "183063/183063 - 155s - loss: 3.8086 - accuracy: 0.3341 - 155s/epoch - 847us/step\n",
      "Epoch 4/20\n",
      "183063/183063 - 156s - loss: 3.8058 - accuracy: 0.3341 - 156s/epoch - 850us/step\n",
      "Epoch 5/20\n",
      "183063/183063 - 155s - loss: 3.8033 - accuracy: 0.3340 - 155s/epoch - 844us/step\n",
      "Epoch 6/20\n",
      "183063/183063 - 155s - loss: 3.8105 - accuracy: 0.3341 - 155s/epoch - 848us/step\n",
      "Epoch 7/20\n",
      "183063/183063 - 154s - loss: 3.8016 - accuracy: 0.3341 - 154s/epoch - 842us/step\n",
      "Epoch 8/20\n",
      "183063/183063 - 155s - loss: 3.8057 - accuracy: 0.3342 - 155s/epoch - 844us/step\n",
      "Epoch 9/20\n",
      "183063/183063 - 155s - loss: 3.8070 - accuracy: 0.3342 - 155s/epoch - 845us/step\n",
      "Epoch 10/20\n",
      "183063/183063 - 155s - loss: 3.8041 - accuracy: 0.3341 - 155s/epoch - 846us/step\n",
      "Epoch 11/20\n",
      "183063/183063 - 154s - loss: 3.8033 - accuracy: 0.3340 - 154s/epoch - 842us/step\n",
      "Epoch 12/20\n",
      "183063/183063 - 155s - loss: 3.8131 - accuracy: 0.3341 - 155s/epoch - 849us/step\n",
      "Epoch 13/20\n",
      "183063/183063 - 155s - loss: 3.8049 - accuracy: 0.3339 - 155s/epoch - 846us/step\n",
      "Epoch 14/20\n",
      "183063/183063 - 155s - loss: 3.8050 - accuracy: 0.3341 - 155s/epoch - 845us/step\n",
      "Epoch 15/20\n",
      "183063/183063 - 155s - loss: 3.8044 - accuracy: 0.3341 - 155s/epoch - 847us/step\n",
      "Epoch 16/20\n",
      "183063/183063 - 155s - loss: 3.8026 - accuracy: 0.3341 - 155s/epoch - 849us/step\n",
      "Epoch 17/20\n",
      "183063/183063 - 155s - loss: 3.8043 - accuracy: 0.3341 - 155s/epoch - 847us/step\n",
      "Epoch 18/20\n",
      "183063/183063 - 155s - loss: 3.8062 - accuracy: 0.3341 - 155s/epoch - 845us/step\n",
      "Epoch 19/20\n",
      "183063/183063 - 156s - loss: 3.8004 - accuracy: 0.3341 - 156s/epoch - 853us/step\n",
      "Epoch 20/20\n",
      "183063/183063 - 155s - loss: 3.8076 - accuracy: 0.3341 - 155s/epoch - 846us/step\n",
      "Epoch 1/20\n",
      "183063/183063 - 155s - loss: 3.7872 - accuracy: 0.3343 - 155s/epoch - 844us/step\n",
      "Epoch 2/20\n",
      "183063/183063 - 155s - loss: 3.7940 - accuracy: 0.3343 - 155s/epoch - 846us/step\n",
      "Epoch 3/20\n",
      "183063/183063 - 154s - loss: 3.7927 - accuracy: 0.3342 - 154s/epoch - 844us/step\n",
      "Epoch 4/20\n",
      "183063/183063 - 155s - loss: 3.7953 - accuracy: 0.3343 - 155s/epoch - 845us/step\n",
      "Epoch 5/20\n",
      "183063/183063 - 156s - loss: 3.7919 - accuracy: 0.3343 - 156s/epoch - 855us/step\n",
      "Epoch 6/20\n",
      "183063/183063 - 154s - loss: 3.7902 - accuracy: 0.3343 - 154s/epoch - 844us/step\n",
      "Epoch 7/20\n",
      "183063/183063 - 155s - loss: 3.7894 - accuracy: 0.3342 - 155s/epoch - 847us/step\n",
      "Epoch 8/20\n",
      "183063/183063 - 156s - loss: 3.7944 - accuracy: 0.3343 - 156s/epoch - 851us/step\n",
      "Epoch 9/20\n",
      "183063/183063 - 157s - loss: 3.7939 - accuracy: 0.3343 - 157s/epoch - 856us/step\n",
      "Epoch 10/20\n",
      "183063/183063 - 153s - loss: 3.7938 - accuracy: 0.3343 - 153s/epoch - 837us/step\n",
      "Epoch 11/20\n",
      "183063/183063 - 155s - loss: 3.7904 - accuracy: 0.3343 - 155s/epoch - 849us/step\n",
      "Epoch 12/20\n",
      "183063/183063 - 155s - loss: 3.7981 - accuracy: 0.3343 - 155s/epoch - 849us/step\n",
      "Epoch 13/20\n",
      "183063/183063 - 154s - loss: 3.7829 - accuracy: 0.3343 - 154s/epoch - 842us/step\n",
      "Epoch 14/20\n",
      "183063/183063 - 155s - loss: 3.7908 - accuracy: 0.3343 - 155s/epoch - 847us/step\n",
      "Epoch 15/20\n",
      "183063/183063 - 156s - loss: 3.7889 - accuracy: 0.3343 - 156s/epoch - 852us/step\n",
      "Epoch 16/20\n",
      "183063/183063 - 155s - loss: 3.7888 - accuracy: 0.3343 - 155s/epoch - 848us/step\n",
      "Epoch 17/20\n",
      "183063/183063 - 154s - loss: 3.7917 - accuracy: 0.3344 - 154s/epoch - 843us/step\n",
      "Epoch 18/20\n",
      "183063/183063 - 155s - loss: 3.7907 - accuracy: 0.3343 - 155s/epoch - 845us/step\n",
      "Epoch 19/20\n",
      "183063/183063 - 155s - loss: 3.7922 - accuracy: 0.3343 - 155s/epoch - 845us/step\n",
      "Epoch 20/20\n",
      "183063/183063 - 155s - loss: 3.7893 - accuracy: 0.3344 - 155s/epoch - 849us/step\n",
      "Epoch 1/20\n",
      "183063/183063 - 155s - loss: 3.8034 - accuracy: 0.3335 - 155s/epoch - 848us/step\n",
      "Epoch 2/20\n",
      "183063/183063 - 155s - loss: 3.8032 - accuracy: 0.3335 - 155s/epoch - 846us/step\n",
      "Epoch 3/20\n",
      "183063/183063 - 154s - loss: 3.8034 - accuracy: 0.3335 - 154s/epoch - 843us/step\n",
      "Epoch 4/20\n",
      "183063/183063 - 156s - loss: 3.8056 - accuracy: 0.3335 - 156s/epoch - 851us/step\n",
      "Epoch 5/20\n",
      "183063/183063 - 155s - loss: 3.8088 - accuracy: 0.3334 - 155s/epoch - 844us/step\n",
      "Epoch 6/20\n",
      "183063/183063 - 155s - loss: 3.8051 - accuracy: 0.3334 - 155s/epoch - 847us/step\n",
      "Epoch 7/20\n",
      "183063/183063 - 155s - loss: 3.8042 - accuracy: 0.3334 - 155s/epoch - 848us/step\n",
      "Epoch 8/20\n",
      "183063/183063 - 157s - loss: 3.8040 - accuracy: 0.3335 - 157s/epoch - 857us/step\n",
      "Epoch 9/20\n",
      "183063/183063 - 156s - loss: 3.8060 - accuracy: 0.3335 - 156s/epoch - 852us/step\n",
      "Epoch 10/20\n",
      "183063/183063 - 155s - loss: 3.8050 - accuracy: 0.3335 - 155s/epoch - 845us/step\n",
      "Epoch 11/20\n",
      "183063/183063 - 156s - loss: 3.8033 - accuracy: 0.3335 - 156s/epoch - 852us/step\n",
      "Epoch 12/20\n",
      "183063/183063 - 157s - loss: 3.8078 - accuracy: 0.3336 - 157s/epoch - 856us/step\n",
      "Epoch 13/20\n",
      "183063/183063 - 156s - loss: 3.8036 - accuracy: 0.3335 - 156s/epoch - 855us/step\n",
      "Epoch 14/20\n",
      "183063/183063 - 156s - loss: 3.8031 - accuracy: 0.3335 - 156s/epoch - 853us/step\n",
      "Epoch 15/20\n",
      "183063/183063 - 155s - loss: 3.8079 - accuracy: 0.3334 - 155s/epoch - 847us/step\n",
      "Epoch 16/20\n",
      "183063/183063 - 156s - loss: 3.8119 - accuracy: 0.3334 - 156s/epoch - 854us/step\n",
      "Epoch 17/20\n",
      "183063/183063 - 155s - loss: 3.8063 - accuracy: 0.3334 - 155s/epoch - 849us/step\n",
      "Epoch 18/20\n",
      "183063/183063 - 157s - loss: 3.8058 - accuracy: 0.3334 - 157s/epoch - 855us/step\n",
      "Epoch 19/20\n",
      "183063/183063 - 155s - loss: 3.8095 - accuracy: 0.3335 - 155s/epoch - 849us/step\n",
      "Epoch 20/20\n",
      "183063/183063 - 156s - loss: 3.8059 - accuracy: 0.3334 - 156s/epoch - 853us/step\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 3.929713726043701 - Accuracy: 33.080968260765076%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 3.811777114868164 - Accuracy: 33.44476819038391%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 3.838092088699341 - Accuracy: 32.98756182193756%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 3.889436960220337 - Accuracy: 33.82497429847717%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 3.8923304080963135 - Accuracy: 33.4119975566864%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6 - Loss: 3.832803249359131 - Accuracy: 33.69714915752411%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7 - Loss: 3.935237407684326 - Accuracy: 33.68239998817444%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8 - Loss: 3.6825308799743652 - Accuracy: 33.02359879016876%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9 - Loss: 3.8377845287323 - Accuracy: 32.83185958862305%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 3.6640889644622803 - Accuracy: 33.564403653144836%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 33.35496813058853 (+- 0.33074105119356434)\n",
      "> Loss: 3.831379532814026\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "met1 = dataset[[col for col in dataset.columns if col in cols]]\n",
    "\n",
    "X = met1.drop(columns=[\"Count\"])\n",
    "y = met1[\"Count\"]\n",
    "\n",
    "X = np.reshape(X.values, (X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = GroupKFold(n_splits=10)\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1,met1.shape[1]-1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for train, test in kfold.split(X, y):\n",
    "    model.fit(X[train], y[train], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "    # Generate generalization metrics   \n",
    "    scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "mean = np.mean(loss_per_fold)\n",
    "print(f'> Loss: {mean}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
