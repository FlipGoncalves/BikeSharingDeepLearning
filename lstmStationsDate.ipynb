{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 10:11:46.864630: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-10 10:11:46.976949: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-10 10:11:46.978276: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-10 10:11:47.967989: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./StationDateDatasets/datasetStationDate.csv\").drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = pd.read_csv(\"./CSVFiles/datatrips.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "day = []\n",
    "year = []\n",
    "for trip in trips.values:\n",
    "    date = datetime.strptime(trip[0], \"%Y-%m-%d %H:%M:%S\").timetuple()\n",
    "    day.append(date.tm_yday)\n",
    "    year.append(date.tm_year)\n",
    "\n",
    "trips = trips.drop(columns=[\"DateEnd\"])\n",
    "trips[\"Day\"] = day\n",
    "trips[\"Year\"] = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame({\"Holiday\": [], \"Weekday\": [], \"Workingday\": [], \"WeatherSituation\": [], \"Temp\": [], \"ATemp\": [], \"Humidity\": [], \"Windspeed\": []})\n",
    "\n",
    "for data in dataset.values:\n",
    "    hour = data[0]\n",
    "    station = data[1]\n",
    "    day = data[3]\n",
    "    year = data[4]\n",
    "\n",
    "    df = trips.loc[(trips[\"StationEnd\"] == station) & (trips[\"Day\"] == day) & (trips[\"Year\"] == year) & (trips[\"Hour\"] == hour)].values[0][6:-1]\n",
    "    new_data.loc[len(new_data)] = df\n",
    "\n",
    "dataset = dataset.join(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"./StationDateDatasets/datasetStationDate.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Temp', 7854.233184039789),\n",
      " ('ATemp', 7706.912809130377),\n",
      " ('Year', 5350.628642028699),\n",
      " ('Humidity', 5196.287790444266),\n",
      " ('Hour', 2591.040359724638),\n",
      " ('WeatherSituation', 1576.8091838740354),\n",
      " ('Windspeed', 261.06541187993037),\n",
      " ('Day', 225.13003715150458),\n",
      " ('StationEnd', 215.19085620330532),\n",
      " ('Workingday', 72.2059928262909),\n",
      " ('Holiday', 60.46833284115195),\n",
      " ('Weekday', 48.945415173314345)]\n"
     ]
    }
   ],
   "source": [
    "def featureSelect_dataframe(X, y, criteria, k):\n",
    "\n",
    "    # initialize our function/method\n",
    "    reg = SelectKBest(criteria, k=k).fit(X,y)\n",
    "    \n",
    "    # transform after creating the reg (so we can use getsupport)\n",
    "    X_transformed = reg.transform(X)\n",
    "\n",
    "    # filter down X based on kept columns\n",
    "    X = X[[val for i,val in enumerate(X.columns) if reg.get_support()[i]]]\n",
    "\n",
    "    # return that dataframe\n",
    "    return X, reg.scores_\n",
    "\n",
    "X = dataset[[col for col in dataset.columns if \"Count\" not in col]]\n",
    "y = dataset['Count']\n",
    "\n",
    "new_x_data = []\n",
    "\n",
    "# F-value between label/feature for regression tasks.\n",
    "New_X, scoresX = featureSelect_dataframe(X, y, f_regression, 11)\n",
    "new_x_data_1 = {list(X.columns)[x]:scoresX[x] for x in range(0,len(list(X.columns)))}\n",
    "pprint(sorted(new_x_data_1.items(), key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "batch_size = 1\n",
    "verbose = 2\n",
    "\n",
    "MSE = [4.218448305130005, 4.1836066246032715, 6.3516003608703615, 6.35099196434021, 6.350759696960449, 6.349380588531494]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 0\n",
    "Input: c(t), StationEnd\n",
    "\n",
    "Output: c(t+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 15:12:29.319651: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 15:12:29.320629: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 15:12:29.321261: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-10 15:12:29.510140: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 15:12:29.511262: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 15:12:29.512072: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-10 15:12:29.823198: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 15:12:29.824338: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 15:12:29.825075: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m# K-fold Cross Validation model evaluation\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m kfold\u001b[39m.\u001b[39msplit(X, y):\n\u001b[0;32m---> 23\u001b[0m     model_met1\u001b[39m.\u001b[39;49mfit(X[train], y[train], epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m     25\u001b[0m     \u001b[39m# Generate generalization metrics\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     scores \u001b[39m=\u001b[39m model_met1\u001b[39m.\u001b[39mevaluate(X[test], y[test], verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/BikeSharingDeepLearning/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/BikeSharingDeepLearning/venv/lib/python3.8/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Desktop/BikeSharingDeepLearning/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/BikeSharingDeepLearning/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/BikeSharingDeepLearning/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Desktop/BikeSharingDeepLearning/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Desktop/BikeSharingDeepLearning/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/BikeSharingDeepLearning/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Desktop/BikeSharingDeepLearning/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cols = [\"StationEnd\", \"Count\", \"Count1\", \"Count1week\"]\n",
    "\n",
    "met1 = dataset[[col for col in dataset.columns if col in cols]]\n",
    "\n",
    "X = met1.drop(columns=[\"Count\"])\n",
    "y = met1[\"Count\"]\n",
    "\n",
    "X = np.reshape(X.values, (X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "model_met1 = Sequential()\n",
    "model_met1.add(LSTM(4, input_shape=(1,met1.shape[1]-1)))\n",
    "model_met1.add(Dense(1))\n",
    "model_met1.compile(loss='mean_squared_error', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for train, test in kfold.split(X, y):\n",
    "    model_met1.fit(X[train], y[train], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model_met1.evaluate(X[test], y[test], verbose=0)\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Methods')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([\"Regression\", \"LSTM\"], [3.9857409829075623, 4.233919239044189])\n",
    "plt.legend([\"Mean Squared Error\"])\n",
    "plt.xlabel(\"Methods\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1\n",
    "Input: c(t), StationEnd, Temp\n",
    "\n",
    "Output: c(t+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 15:12:37.446684: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 15:12:37.447635: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 15:12:37.448260: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-10 15:12:37.638401: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 15:12:37.639197: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 15:12:37.639984: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-10 15:12:37.951913: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 15:12:37.953035: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 15:12:37.953736: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183062/183062 - 151s - loss: 4.3568 - accuracy: 0.3337 - 151s/epoch - 823us/step\n",
      "Epoch 2/5\n",
      "183062/183062 - 149s - loss: 4.1975 - accuracy: 0.3342 - 149s/epoch - 814us/step\n",
      "Epoch 3/5\n",
      "183062/183062 - 147s - loss: 4.1810 - accuracy: 0.3342 - 147s/epoch - 806us/step\n",
      "Epoch 4/5\n",
      "183062/183062 - 140s - loss: 4.1765 - accuracy: 0.3342 - 140s/epoch - 767us/step\n",
      "Epoch 5/5\n",
      "183062/183062 - 137s - loss: 4.1761 - accuracy: 0.3342 - 137s/epoch - 746us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 15:24:41.824515: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 15:24:41.825644: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 15:24:41.826342: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "183062/183062 - 138s - loss: 4.1755 - accuracy: 0.3341 - 138s/epoch - 754us/step\n",
      "Epoch 2/5\n",
      "183062/183062 - 138s - loss: 4.1770 - accuracy: 0.3341 - 138s/epoch - 752us/step\n",
      "Epoch 3/5\n",
      "183062/183062 - 137s - loss: 4.1708 - accuracy: 0.3341 - 137s/epoch - 747us/step\n",
      "Epoch 4/5\n",
      "183062/183062 - 139s - loss: 4.1698 - accuracy: 0.3341 - 139s/epoch - 758us/step\n",
      "Epoch 5/5\n",
      "183062/183062 - 143s - loss: 4.1719 - accuracy: 0.3341 - 143s/epoch - 783us/step\n",
      "Epoch 1/5\n",
      "183062/183062 - 146s - loss: 4.1815 - accuracy: 0.3340 - 146s/epoch - 800us/step\n",
      "Epoch 2/5\n",
      "183062/183062 - 146s - loss: 4.1821 - accuracy: 0.3340 - 146s/epoch - 799us/step\n",
      "Epoch 3/5\n",
      "183062/183062 - 146s - loss: 4.1822 - accuracy: 0.3340 - 146s/epoch - 799us/step\n",
      "Epoch 4/5\n",
      "183062/183062 - 146s - loss: 4.1789 - accuracy: 0.3340 - 146s/epoch - 799us/step\n",
      "Epoch 5/5\n",
      "183062/183062 - 148s - loss: 4.1781 - accuracy: 0.3340 - 148s/epoch - 808us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 146s - loss: 4.1508 - accuracy: 0.3341 - 146s/epoch - 799us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 145s - loss: 4.1472 - accuracy: 0.3341 - 145s/epoch - 794us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 147s - loss: 4.1479 - accuracy: 0.3341 - 147s/epoch - 806us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 164s - loss: 4.1455 - accuracy: 0.3341 - 164s/epoch - 893us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 162s - loss: 4.1430 - accuracy: 0.3341 - 162s/epoch - 887us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 162s - loss: 4.1539 - accuracy: 0.3332 - 162s/epoch - 884us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 161s - loss: 4.1537 - accuracy: 0.3332 - 161s/epoch - 881us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 161s - loss: 4.1563 - accuracy: 0.3332 - 161s/epoch - 879us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 160s - loss: 4.1513 - accuracy: 0.3332 - 160s/epoch - 874us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 160s - loss: 4.1520 - accuracy: 0.3332 - 160s/epoch - 874us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 162s - loss: 4.1456 - accuracy: 0.3334 - 162s/epoch - 884us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 163s - loss: 4.1518 - accuracy: 0.3334 - 163s/epoch - 890us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 163s - loss: 4.1469 - accuracy: 0.3334 - 163s/epoch - 889us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 161s - loss: 4.1502 - accuracy: 0.3334 - 161s/epoch - 882us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 162s - loss: 4.1498 - accuracy: 0.3334 - 162s/epoch - 883us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 162s - loss: 4.1521 - accuracy: 0.3338 - 162s/epoch - 884us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 162s - loss: 4.1532 - accuracy: 0.3338 - 162s/epoch - 885us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 163s - loss: 4.1557 - accuracy: 0.3338 - 163s/epoch - 890us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 162s - loss: 4.1530 - accuracy: 0.3338 - 162s/epoch - 883us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 160s - loss: 4.1507 - accuracy: 0.3338 - 160s/epoch - 876us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 161s - loss: 4.1776 - accuracy: 0.3337 - 161s/epoch - 882us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 164s - loss: 4.1736 - accuracy: 0.3337 - 164s/epoch - 894us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 162s - loss: 4.1734 - accuracy: 0.3337 - 162s/epoch - 888us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 163s - loss: 4.1740 - accuracy: 0.3337 - 163s/epoch - 891us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 162s - loss: 4.1740 - accuracy: 0.3337 - 162s/epoch - 885us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 163s - loss: 4.1545 - accuracy: 0.3339 - 163s/epoch - 889us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 163s - loss: 4.1573 - accuracy: 0.3339 - 163s/epoch - 889us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 162s - loss: 4.1549 - accuracy: 0.3339 - 162s/epoch - 884us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 162s - loss: 4.1574 - accuracy: 0.3339 - 162s/epoch - 887us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 165s - loss: 4.1541 - accuracy: 0.3339 - 165s/epoch - 899us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 162s - loss: 4.1399 - accuracy: 0.3346 - 162s/epoch - 885us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 161s - loss: 4.1396 - accuracy: 0.3346 - 161s/epoch - 880us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 161s - loss: 4.1412 - accuracy: 0.3346 - 161s/epoch - 879us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 162s - loss: 4.1411 - accuracy: 0.3346 - 162s/epoch - 884us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 163s - loss: 4.1413 - accuracy: 0.3346 - 163s/epoch - 893us/step\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 4.132286548614502 - Accuracy: 33.13013017177582%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 4.0879034996032715 - Accuracy: 33.23337137699127%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 4.051037788391113 - Accuracy: 33.307114243507385%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 4.29300594329834 - Accuracy: 33.23008716106415%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 4.176961421966553 - Accuracy: 34.02163088321686%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6 - Loss: 4.233358860015869 - Accuracy: 33.82989168167114%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7 - Loss: 4.22764778137207 - Accuracy: 33.45132768154144%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8 - Loss: 3.965555429458618 - Accuracy: 33.559489250183105%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9 - Loss: 4.13381814956665 - Accuracy: 33.36283266544342%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 4.290126323699951 - Accuracy: 32.787612080574036%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 33.39134871959686 (+- 0.33362374790055765)\n",
      "> Loss: 4.159170174598694\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cols = [\"StationEnd\", \"Count\", \"Count1\", \"Count1week\", \"Temp\"]\n",
    "\n",
    "met1 = dataset[[col for col in dataset.columns if col in cols]]\n",
    "\n",
    "X = met1.drop(columns=[\"Count\"])\n",
    "y = met1[\"Count\"]\n",
    "\n",
    "X = np.reshape(X.values, (X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "model_met1 = Sequential()\n",
    "model_met1.add(LSTM(4, input_shape=(1,met1.shape[1]-1)))\n",
    "model_met1.add(Dense(1))\n",
    "model_met1.compile(loss='mean_squared_error', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for train, test in kfold.split(X, y):\n",
    "    model_met1.fit(X[train], y[train], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model_met1.evaluate(X[test], y[test], verbose=0)\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "mean = np.mean(loss_per_fold)\n",
    "print(f'> Loss: {mean}')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "MSE.append(mean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2\n",
    "Input: c(t), StationEnd, Temp, ATemp\n",
    "\n",
    "Output: c(t+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 17:22:18.735639: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 17:22:18.736455: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 17:22:18.737231: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-10 17:22:18.915235: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 17:22:18.916103: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 17:22:18.916826: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-10 17:22:19.215340: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 17:22:19.216424: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 17:22:19.217176: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183062/183062 - 165s - loss: 4.3545 - accuracy: 0.3334 - 165s/epoch - 903us/step\n",
      "Epoch 2/5\n",
      "183062/183062 - 164s - loss: 4.2080 - accuracy: 0.3337 - 164s/epoch - 894us/step\n",
      "Epoch 3/5\n",
      "183062/183062 - 164s - loss: 4.1893 - accuracy: 0.3337 - 164s/epoch - 898us/step\n",
      "Epoch 4/5\n",
      "183062/183062 - 165s - loss: 4.1797 - accuracy: 0.3337 - 165s/epoch - 899us/step\n",
      "Epoch 5/5\n",
      "183062/183062 - 163s - loss: 4.1747 - accuracy: 0.3337 - 163s/epoch - 893us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 17:36:00.299006: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 17:36:00.300063: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 17:36:00.300837: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "183062/183062 - 165s - loss: 4.1650 - accuracy: 0.3338 - 165s/epoch - 903us/step\n",
      "Epoch 2/5\n",
      "183062/183062 - 164s - loss: 4.1618 - accuracy: 0.3338 - 164s/epoch - 895us/step\n",
      "Epoch 3/5\n",
      "183062/183062 - 166s - loss: 4.1634 - accuracy: 0.3338 - 166s/epoch - 906us/step\n",
      "Epoch 4/5\n",
      "183062/183062 - 165s - loss: 4.1584 - accuracy: 0.3338 - 165s/epoch - 899us/step\n",
      "Epoch 5/5\n",
      "183062/183062 - 164s - loss: 4.1553 - accuracy: 0.3338 - 164s/epoch - 896us/step\n",
      "Epoch 1/5\n",
      "183062/183062 - 165s - loss: 4.1490 - accuracy: 0.3334 - 165s/epoch - 904us/step\n",
      "Epoch 2/5\n",
      "183062/183062 - 165s - loss: 4.1469 - accuracy: 0.3334 - 165s/epoch - 899us/step\n",
      "Epoch 3/5\n",
      "183062/183062 - 164s - loss: 4.1478 - accuracy: 0.3334 - 164s/epoch - 895us/step\n",
      "Epoch 4/5\n",
      "183062/183062 - 164s - loss: 4.1466 - accuracy: 0.3334 - 164s/epoch - 896us/step\n",
      "Epoch 5/5\n",
      "183062/183062 - 163s - loss: 4.1458 - accuracy: 0.3334 - 163s/epoch - 893us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 164s - loss: 4.1431 - accuracy: 0.3339 - 164s/epoch - 897us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 164s - loss: 4.1434 - accuracy: 0.3339 - 164s/epoch - 896us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 163s - loss: 4.1478 - accuracy: 0.3339 - 163s/epoch - 889us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 164s - loss: 4.1456 - accuracy: 0.3339 - 164s/epoch - 897us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 164s - loss: 4.1472 - accuracy: 0.3339 - 164s/epoch - 894us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 162s - loss: 4.1446 - accuracy: 0.3343 - 162s/epoch - 888us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 164s - loss: 4.1488 - accuracy: 0.3343 - 164s/epoch - 893us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 165s - loss: 4.1461 - accuracy: 0.3343 - 165s/epoch - 902us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 164s - loss: 4.1494 - accuracy: 0.3343 - 164s/epoch - 894us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 164s - loss: 4.1442 - accuracy: 0.3343 - 164s/epoch - 895us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 164s - loss: 4.1348 - accuracy: 0.3342 - 164s/epoch - 895us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 163s - loss: 4.1367 - accuracy: 0.3342 - 163s/epoch - 891us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 164s - loss: 4.1369 - accuracy: 0.3342 - 164s/epoch - 896us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 166s - loss: 4.1375 - accuracy: 0.3342 - 166s/epoch - 905us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 164s - loss: 4.1334 - accuracy: 0.3342 - 164s/epoch - 898us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 163s - loss: 4.1306 - accuracy: 0.3343 - 163s/epoch - 893us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 163s - loss: 4.1375 - accuracy: 0.3343 - 163s/epoch - 891us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 163s - loss: 4.1351 - accuracy: 0.3343 - 163s/epoch - 892us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 163s - loss: 4.1346 - accuracy: 0.3343 - 163s/epoch - 891us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 162s - loss: 4.1353 - accuracy: 0.3343 - 162s/epoch - 885us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 162s - loss: 4.1296 - accuracy: 0.3341 - 162s/epoch - 886us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 164s - loss: 4.1267 - accuracy: 0.3341 - 164s/epoch - 897us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 162s - loss: 4.1246 - accuracy: 0.3341 - 162s/epoch - 885us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 164s - loss: 4.1270 - accuracy: 0.3340 - 164s/epoch - 895us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 163s - loss: 4.1278 - accuracy: 0.3341 - 163s/epoch - 889us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 164s - loss: 4.1531 - accuracy: 0.3334 - 164s/epoch - 894us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 163s - loss: 4.1476 - accuracy: 0.3334 - 163s/epoch - 889us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 164s - loss: 4.1464 - accuracy: 0.3334 - 164s/epoch - 896us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 163s - loss: 4.1510 - accuracy: 0.3334 - 163s/epoch - 889us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 163s - loss: 4.1481 - accuracy: 0.3334 - 163s/epoch - 890us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 163s - loss: 4.1454 - accuracy: 0.3341 - 163s/epoch - 889us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 162s - loss: 4.1478 - accuracy: 0.3341 - 162s/epoch - 888us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 164s - loss: 4.1455 - accuracy: 0.3341 - 164s/epoch - 893us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 164s - loss: 4.1415 - accuracy: 0.3341 - 164s/epoch - 896us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 163s - loss: 4.1466 - accuracy: 0.3341 - 163s/epoch - 888us/step\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 4.0815277099609375 - Accuracy: 33.57750475406647%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 4.052795886993408 - Accuracy: 33.493927121162415%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 4.116003036499023 - Accuracy: 33.82822871208191%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 4.101836204528809 - Accuracy: 33.43657851219177%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 4.129080772399902 - Accuracy: 33.02359879016876%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6 - Loss: 4.1874566078186035 - Accuracy: 33.161258697509766%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7 - Loss: 4.239480972290039 - Accuracy: 33.077678084373474%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8 - Loss: 4.266186237335205 - Accuracy: 33.24975371360779%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9 - Loss: 4.165367126464844 - Accuracy: 33.869221806526184%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 4.159633159637451 - Accuracy: 33.195674419403076%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 33.39134246110916 (+- 0.2848433288960809)\n",
      "> Loss: 4.149936771392822\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cols = [\"StationEnd\", \"Count\", \"Count1\", \"Count1week\", \"Temp\", \"ATemp\"]\n",
    "\n",
    "met1 = dataset[[col for col in dataset.columns if col in cols]]\n",
    "\n",
    "X = met1.drop(columns=[\"Count\"])\n",
    "y = met1[\"Count\"]\n",
    "\n",
    "X = np.reshape(X.values, (X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "model_met1 = Sequential()\n",
    "model_met1.add(LSTM(4, input_shape=(1,met1.shape[1]-1)))\n",
    "model_met1.add(Dense(1))\n",
    "model_met1.compile(loss='mean_squared_error', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for train, test in kfold.split(X, y):\n",
    "    model_met1.fit(X[train], y[train], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model_met1.evaluate(X[test], y[test], verbose=0)\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "mean = np.mean(loss_per_fold)\n",
    "print(f'> Loss: {mean}')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "MSE.append(mean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3\n",
    "Input: c(t), StationEnd, Temp, ATemp, Year\n",
    "\n",
    "Output: c(t+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 19:38:49.640877: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 19:38:49.641816: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 19:38:49.642427: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-10 19:38:49.814171: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 19:38:49.815032: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 19:38:49.815693: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-10 19:38:50.106898: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 19:38:50.107994: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 19:38:50.108682: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183062/183062 - 164s - loss: 6.4351 - accuracy: 0.3324 - 164s/epoch - 897us/step\n",
      "Epoch 2/5\n",
      "183062/183062 - 165s - loss: 6.3446 - accuracy: 0.3336 - 165s/epoch - 902us/step\n",
      "Epoch 3/5\n",
      "183062/183062 - 163s - loss: 6.3443 - accuracy: 0.3336 - 163s/epoch - 890us/step\n",
      "Epoch 4/5\n",
      "183062/183062 - 164s - loss: 6.3444 - accuracy: 0.3336 - 164s/epoch - 894us/step\n",
      "Epoch 5/5\n",
      "183062/183062 - 163s - loss: 6.3444 - accuracy: 0.3336 - 163s/epoch - 888us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 19:52:28.283368: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 19:52:28.284511: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 19:52:28.285197: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "183062/183062 - 165s - loss: 6.3373 - accuracy: 0.3343 - 165s/epoch - 900us/step\n",
      "Epoch 2/5\n",
      "183062/183062 - 165s - loss: 6.3379 - accuracy: 0.3343 - 165s/epoch - 899us/step\n",
      "Epoch 3/5\n",
      "183062/183062 - 165s - loss: 6.3377 - accuracy: 0.3343 - 165s/epoch - 899us/step\n",
      "Epoch 4/5\n",
      "183062/183062 - 165s - loss: 6.3382 - accuracy: 0.3343 - 165s/epoch - 900us/step\n",
      "Epoch 5/5\n",
      "183062/183062 - 163s - loss: 6.3379 - accuracy: 0.3343 - 163s/epoch - 891us/step\n",
      "Epoch 1/5\n",
      "183062/183062 - 163s - loss: 6.3404 - accuracy: 0.3340 - 163s/epoch - 892us/step\n",
      "Epoch 2/5\n",
      "183062/183062 - 164s - loss: 6.3405 - accuracy: 0.3340 - 164s/epoch - 894us/step\n",
      "Epoch 3/5\n",
      "183062/183062 - 163s - loss: 6.3401 - accuracy: 0.3340 - 163s/epoch - 891us/step\n",
      "Epoch 4/5\n",
      "183062/183062 - 164s - loss: 6.3404 - accuracy: 0.3340 - 164s/epoch - 896us/step\n",
      "Epoch 5/5\n",
      "183062/183062 - 164s - loss: 6.3406 - accuracy: 0.3340 - 164s/epoch - 895us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 163s - loss: 6.3510 - accuracy: 0.3340 - 163s/epoch - 892us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 164s - loss: 6.3514 - accuracy: 0.3340 - 164s/epoch - 897us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 163s - loss: 6.3506 - accuracy: 0.3340 - 163s/epoch - 889us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 163s - loss: 6.3510 - accuracy: 0.3340 - 163s/epoch - 892us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 164s - loss: 6.3509 - accuracy: 0.3340 - 164s/epoch - 894us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 162s - loss: 6.3726 - accuracy: 0.3340 - 162s/epoch - 886us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 163s - loss: 6.3726 - accuracy: 0.3340 - 163s/epoch - 889us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 163s - loss: 6.3728 - accuracy: 0.3340 - 163s/epoch - 892us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 165s - loss: 6.3728 - accuracy: 0.3340 - 165s/epoch - 903us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 162s - loss: 6.3728 - accuracy: 0.3340 - 162s/epoch - 883us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 164s - loss: 6.3288 - accuracy: 0.3340 - 164s/epoch - 898us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 162s - loss: 6.3290 - accuracy: 0.3340 - 162s/epoch - 885us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 162s - loss: 6.3289 - accuracy: 0.3340 - 162s/epoch - 887us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 164s - loss: 6.3286 - accuracy: 0.3340 - 164s/epoch - 896us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 163s - loss: 6.3286 - accuracy: 0.3340 - 163s/epoch - 892us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 164s - loss: 6.3548 - accuracy: 0.3333 - 164s/epoch - 897us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 164s - loss: 6.3550 - accuracy: 0.3333 - 164s/epoch - 893us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 164s - loss: 6.3550 - accuracy: 0.3333 - 164s/epoch - 895us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 162s - loss: 6.3545 - accuracy: 0.3333 - 162s/epoch - 884us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 164s - loss: 6.3548 - accuracy: 0.3333 - 164s/epoch - 896us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 165s - loss: 6.3455 - accuracy: 0.3341 - 165s/epoch - 901us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 163s - loss: 6.3456 - accuracy: 0.3341 - 163s/epoch - 888us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 163s - loss: 6.3457 - accuracy: 0.3341 - 163s/epoch - 891us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 163s - loss: 6.3457 - accuracy: 0.3341 - 163s/epoch - 892us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 164s - loss: 6.3457 - accuracy: 0.3341 - 164s/epoch - 895us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 166s - loss: 6.3616 - accuracy: 0.3340 - 166s/epoch - 906us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 162s - loss: 6.3611 - accuracy: 0.3340 - 162s/epoch - 887us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 162s - loss: 6.3615 - accuracy: 0.3340 - 162s/epoch - 887us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 162s - loss: 6.3612 - accuracy: 0.3340 - 162s/epoch - 887us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 163s - loss: 6.3611 - accuracy: 0.3340 - 163s/epoch - 890us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 161s - loss: 6.3577 - accuracy: 0.3338 - 161s/epoch - 882us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 163s - loss: 6.3576 - accuracy: 0.3338 - 163s/epoch - 889us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 162s - loss: 6.3573 - accuracy: 0.3338 - 162s/epoch - 885us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 163s - loss: 6.3573 - accuracy: 0.3338 - 163s/epoch - 892us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 163s - loss: 6.3572 - accuracy: 0.3338 - 163s/epoch - 891us/step\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 6.392772197723389 - Accuracy: 33.66599380970001%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 6.453035354614258 - Accuracy: 33.00722539424896%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 6.437191486358643 - Accuracy: 33.34644436836243%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 6.335101127624512 - Accuracy: 33.30383598804474%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 6.149058818817139 - Accuracy: 33.30875039100647%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6 - Loss: 6.535610198974609 - Accuracy: 33.35791528224945%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7 - Loss: 6.302570343017578 - Accuracy: 33.903637528419495%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8 - Loss: 6.382539749145508 - Accuracy: 33.24975371360779%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9 - Loss: 6.244060516357422 - Accuracy: 33.29891860485077%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 6.27617073059082 - Accuracy: 33.47099423408508%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 33.39134693145752 (+- 0.23194212976094655)\n",
      "> Loss: 6.3508110523223875\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cols = [\"StationEnd\", \"Count\", \"Count1\", \"Count1week\", \"Temp\", \"ATemp\", \"Year\"]\n",
    "\n",
    "met1 = dataset[[col for col in dataset.columns if col in cols]]\n",
    "\n",
    "X = met1.drop(columns=[\"Count\"])\n",
    "y = met1[\"Count\"]\n",
    "\n",
    "X = np.reshape(X.values, (X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "model_met1 = Sequential()\n",
    "model_met1.add(LSTM(4, input_shape=(1,met1.shape[1]-1)))\n",
    "model_met1.add(Dense(1))\n",
    "model_met1.compile(loss='mean_squared_error', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for train, test in kfold.split(X, y):\n",
    "    model_met1.fit(X[train], y[train], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model_met1.evaluate(X[test], y[test], verbose=0)\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "mean = np.mean(loss_per_fold)\n",
    "print(f'> Loss: {mean}')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "MSE.append(mean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4\n",
    "Input: c(t), StationEnd, Temp, ATemp, Year, Humidity\n",
    "\n",
    "Output: c(t+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 21:55:04.387354: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 21:55:04.388143: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 21:55:04.388948: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-10 21:55:04.561897: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 21:55:04.562719: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 21:55:04.563448: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-10 21:55:04.866068: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 21:55:04.867170: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 21:55:04.867857: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183062/183062 - 166s - loss: 6.4327 - accuracy: 0.3320 - 166s/epoch - 904us/step\n",
      "Epoch 2/5\n",
      "183062/183062 - 164s - loss: 6.3513 - accuracy: 0.3336 - 164s/epoch - 894us/step\n",
      "Epoch 3/5\n",
      "183062/183062 - 164s - loss: 6.3522 - accuracy: 0.3336 - 164s/epoch - 895us/step\n",
      "Epoch 4/5\n",
      "183062/183062 - 162s - loss: 6.3517 - accuracy: 0.3336 - 162s/epoch - 885us/step\n",
      "Epoch 5/5\n",
      "183062/183062 - 164s - loss: 6.3518 - accuracy: 0.3336 - 164s/epoch - 894us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 22:08:43.345607: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 22:08:43.346537: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 22:08:43.347161: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "183062/183062 - 165s - loss: 6.3340 - accuracy: 0.3339 - 165s/epoch - 902us/step\n",
      "Epoch 2/5\n",
      "183062/183062 - 163s - loss: 6.3331 - accuracy: 0.3339 - 163s/epoch - 890us/step\n",
      "Epoch 3/5\n",
      "183062/183062 - 164s - loss: 6.3340 - accuracy: 0.3339 - 164s/epoch - 894us/step\n",
      "Epoch 4/5\n",
      "183062/183062 - 164s - loss: 6.3333 - accuracy: 0.3339 - 164s/epoch - 895us/step\n",
      "Epoch 5/5\n",
      "183062/183062 - 164s - loss: 6.3337 - accuracy: 0.3339 - 164s/epoch - 895us/step\n",
      "Epoch 1/5\n",
      "183062/183062 - 166s - loss: 6.3505 - accuracy: 0.3339 - 166s/epoch - 904us/step\n",
      "Epoch 2/5\n",
      "183062/183062 - 162s - loss: 6.3510 - accuracy: 0.3339 - 162s/epoch - 884us/step\n",
      "Epoch 3/5\n",
      "183062/183062 - 165s - loss: 6.3503 - accuracy: 0.3339 - 165s/epoch - 900us/step\n",
      "Epoch 4/5\n",
      "183062/183062 - 163s - loss: 6.3510 - accuracy: 0.3339 - 163s/epoch - 892us/step\n",
      "Epoch 5/5\n",
      "183062/183062 - 163s - loss: 6.3505 - accuracy: 0.3339 - 163s/epoch - 889us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 162s - loss: 6.3526 - accuracy: 0.3330 - 162s/epoch - 887us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 165s - loss: 6.3530 - accuracy: 0.3330 - 165s/epoch - 899us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 164s - loss: 6.3533 - accuracy: 0.3330 - 164s/epoch - 898us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 163s - loss: 6.3532 - accuracy: 0.3330 - 163s/epoch - 892us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 164s - loss: 6.3531 - accuracy: 0.3330 - 164s/epoch - 896us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 162s - loss: 6.3434 - accuracy: 0.3338 - 162s/epoch - 886us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 163s - loss: 6.3439 - accuracy: 0.3338 - 163s/epoch - 892us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 165s - loss: 6.3438 - accuracy: 0.3338 - 165s/epoch - 902us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 162s - loss: 6.3438 - accuracy: 0.3338 - 162s/epoch - 886us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 163s - loss: 6.3436 - accuracy: 0.3338 - 163s/epoch - 891us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 165s - loss: 6.3302 - accuracy: 0.3340 - 165s/epoch - 899us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 163s - loss: 6.3300 - accuracy: 0.3340 - 163s/epoch - 888us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 163s - loss: 6.3295 - accuracy: 0.3340 - 163s/epoch - 889us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 162s - loss: 6.3299 - accuracy: 0.3340 - 162s/epoch - 887us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 163s - loss: 6.3297 - accuracy: 0.3340 - 163s/epoch - 891us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 163s - loss: 6.3721 - accuracy: 0.3341 - 163s/epoch - 891us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 161s - loss: 6.3719 - accuracy: 0.3341 - 161s/epoch - 880us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 161s - loss: 6.3725 - accuracy: 0.3341 - 161s/epoch - 882us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 162s - loss: 6.3719 - accuracy: 0.3341 - 162s/epoch - 882us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 164s - loss: 6.3721 - accuracy: 0.3341 - 164s/epoch - 894us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 163s - loss: 6.3466 - accuracy: 0.3341 - 163s/epoch - 893us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 163s - loss: 6.3467 - accuracy: 0.3341 - 163s/epoch - 893us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 162s - loss: 6.3469 - accuracy: 0.3341 - 162s/epoch - 887us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 163s - loss: 6.3472 - accuracy: 0.3341 - 163s/epoch - 889us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 163s - loss: 6.3467 - accuracy: 0.3341 - 163s/epoch - 889us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 162s - loss: 6.3594 - accuracy: 0.3345 - 162s/epoch - 887us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 163s - loss: 6.3590 - accuracy: 0.3345 - 163s/epoch - 890us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 164s - loss: 6.3592 - accuracy: 0.3345 - 164s/epoch - 894us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 164s - loss: 6.3588 - accuracy: 0.3345 - 164s/epoch - 894us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 162s - loss: 6.3592 - accuracy: 0.3345 - 162s/epoch - 886us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 163s - loss: 6.3634 - accuracy: 0.3342 - 163s/epoch - 889us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 165s - loss: 6.3636 - accuracy: 0.3342 - 165s/epoch - 900us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 163s - loss: 6.3632 - accuracy: 0.3342 - 163s/epoch - 890us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 163s - loss: 6.3628 - accuracy: 0.3342 - 163s/epoch - 893us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 162s - loss: 6.3629 - accuracy: 0.3342 - 162s/epoch - 887us/step\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 6.339531898498535 - Accuracy: 33.63158106803894%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 6.498668193817139 - Accuracy: 33.40543806552887%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 6.349573135375977 - Accuracy: 33.36119055747986%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 6.324885845184326 - Accuracy: 34.20845568180084%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 6.411462306976318 - Accuracy: 33.510324358940125%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6 - Loss: 6.537492275238037 - Accuracy: 33.29891860485077%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7 - Loss: 6.152673244476318 - Accuracy: 33.23008716106415%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8 - Loss: 6.3833327293396 - Accuracy: 33.23992192745209%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9 - Loss: 6.275991916656494 - Accuracy: 32.90068805217743%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 6.237298965454102 - Accuracy: 33.126842975616455%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 33.39134484529495 (+- 0.3329907603584611)\n",
      "> Loss: 6.351091051101685\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cols = [\"StationEnd\", \"Count\", \"Count1\", \"Count1week\", \"Temp\", \"ATemp\", \"Year\", \"Humidity\"]\n",
    "\n",
    "met1 = dataset[[col for col in dataset.columns if col in cols]]\n",
    "\n",
    "X = met1.drop(columns=[\"Count\"])\n",
    "y = met1[\"Count\"]\n",
    "\n",
    "X = np.reshape(X.values, (X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "model_met1 = Sequential()\n",
    "model_met1.add(LSTM(4, input_shape=(1,met1.shape[1]-1)))\n",
    "model_met1.add(Dense(1))\n",
    "model_met1.compile(loss='mean_squared_error', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for train, test in kfold.split(X, y):\n",
    "    model_met1.fit(X[train], y[train], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model_met1.evaluate(X[test], y[test], verbose=0)\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "mean = np.mean(loss_per_fold)\n",
    "print(f'> Loss: {mean}')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "MSE.append(mean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 5\n",
    "Input: c(t), StationEnd, Temp, ATemp, Year, Humidity, Day\n",
    "\n",
    "Output: c(t+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 00:11:11.927263: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 00:11:11.928605: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 00:11:11.929236: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-11 00:11:12.089202: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 00:11:12.089956: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 00:11:12.090622: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-11 00:11:12.368669: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 00:11:12.369905: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 00:11:12.370594: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183062/183062 - 163s - loss: 6.3768 - accuracy: 0.3337 - 163s/epoch - 892us/step\n",
      "Epoch 2/5\n",
      "183062/183062 - 161s - loss: 6.3535 - accuracy: 0.3338 - 161s/epoch - 880us/step\n",
      "Epoch 3/5\n",
      "183062/183062 - 160s - loss: 6.3539 - accuracy: 0.3338 - 160s/epoch - 874us/step\n",
      "Epoch 4/5\n",
      "183062/183062 - 163s - loss: 6.3534 - accuracy: 0.3338 - 163s/epoch - 889us/step\n",
      "Epoch 5/5\n",
      "183062/183062 - 160s - loss: 6.3536 - accuracy: 0.3338 - 160s/epoch - 874us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 00:24:39.354072: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 00:24:39.355077: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 00:24:39.355727: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "183062/183062 - 160s - loss: 6.3273 - accuracy: 0.3342 - 160s/epoch - 876us/step\n",
      "Epoch 2/5\n",
      "183062/183062 - 162s - loss: 6.3276 - accuracy: 0.3342 - 162s/epoch - 884us/step\n",
      "Epoch 3/5\n",
      "183062/183062 - 160s - loss: 6.3277 - accuracy: 0.3342 - 160s/epoch - 875us/step\n",
      "Epoch 4/5\n",
      "183062/183062 - 164s - loss: 6.3276 - accuracy: 0.3342 - 164s/epoch - 894us/step\n",
      "Epoch 5/5\n",
      "183062/183062 - 163s - loss: 6.3274 - accuracy: 0.3342 - 163s/epoch - 888us/step\n",
      "Epoch 1/5\n",
      "183062/183062 - 163s - loss: 6.3730 - accuracy: 0.3344 - 163s/epoch - 893us/step\n",
      "Epoch 2/5\n",
      "183062/183062 - 161s - loss: 6.3723 - accuracy: 0.3344 - 161s/epoch - 877us/step\n",
      "Epoch 3/5\n",
      "183062/183062 - 163s - loss: 6.3726 - accuracy: 0.3344 - 163s/epoch - 888us/step\n",
      "Epoch 4/5\n",
      "183062/183062 - 161s - loss: 6.3722 - accuracy: 0.3344 - 161s/epoch - 882us/step\n",
      "Epoch 5/5\n",
      "183062/183062 - 160s - loss: 6.3728 - accuracy: 0.3344 - 160s/epoch - 872us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 162s - loss: 6.3511 - accuracy: 0.3337 - 162s/epoch - 886us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 161s - loss: 6.3512 - accuracy: 0.3337 - 161s/epoch - 881us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 162s - loss: 6.3519 - accuracy: 0.3337 - 162s/epoch - 887us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 162s - loss: 6.3513 - accuracy: 0.3337 - 162s/epoch - 884us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 163s - loss: 6.3516 - accuracy: 0.3337 - 163s/epoch - 890us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 163s - loss: 6.3555 - accuracy: 0.3340 - 163s/epoch - 889us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 163s - loss: 6.3550 - accuracy: 0.3340 - 163s/epoch - 889us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 160s - loss: 6.3547 - accuracy: 0.3340 - 160s/epoch - 876us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 161s - loss: 6.3547 - accuracy: 0.3340 - 161s/epoch - 881us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 162s - loss: 6.3552 - accuracy: 0.3340 - 162s/epoch - 885us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 161s - loss: 6.3547 - accuracy: 0.3337 - 161s/epoch - 881us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 162s - loss: 6.3549 - accuracy: 0.3337 - 162s/epoch - 887us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 163s - loss: 6.3547 - accuracy: 0.3337 - 163s/epoch - 893us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 163s - loss: 6.3544 - accuracy: 0.3337 - 163s/epoch - 888us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 163s - loss: 6.3547 - accuracy: 0.3337 - 163s/epoch - 893us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 161s - loss: 6.3631 - accuracy: 0.3338 - 161s/epoch - 880us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 164s - loss: 6.3630 - accuracy: 0.3338 - 164s/epoch - 893us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 162s - loss: 6.3628 - accuracy: 0.3338 - 162s/epoch - 885us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 162s - loss: 6.3627 - accuracy: 0.3338 - 162s/epoch - 887us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 161s - loss: 6.3631 - accuracy: 0.3338 - 161s/epoch - 880us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 161s - loss: 6.3409 - accuracy: 0.3336 - 161s/epoch - 882us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 162s - loss: 6.3411 - accuracy: 0.3336 - 162s/epoch - 887us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 162s - loss: 6.3413 - accuracy: 0.3336 - 162s/epoch - 888us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 164s - loss: 6.3409 - accuracy: 0.3336 - 164s/epoch - 894us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 162s - loss: 6.3409 - accuracy: 0.3336 - 162s/epoch - 885us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 163s - loss: 6.3380 - accuracy: 0.3340 - 163s/epoch - 890us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 162s - loss: 6.3379 - accuracy: 0.3340 - 162s/epoch - 886us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 161s - loss: 6.3363 - accuracy: 0.3340 - 161s/epoch - 881us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 161s - loss: 6.3376 - accuracy: 0.3340 - 161s/epoch - 882us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 163s - loss: 6.3374 - accuracy: 0.3340 - 163s/epoch - 891us/step\n",
      "Epoch 1/5\n",
      "183063/183063 - 161s - loss: 6.3566 - accuracy: 0.3339 - 161s/epoch - 881us/step\n",
      "Epoch 2/5\n",
      "183063/183063 - 161s - loss: 6.3564 - accuracy: 0.3339 - 161s/epoch - 879us/step\n",
      "Epoch 3/5\n",
      "183063/183063 - 164s - loss: 6.3567 - accuracy: 0.3339 - 164s/epoch - 898us/step\n",
      "Epoch 4/5\n",
      "183063/183063 - 160s - loss: 6.3564 - accuracy: 0.3339 - 160s/epoch - 872us/step\n",
      "Epoch 5/5\n",
      "183063/183063 - 163s - loss: 6.3565 - accuracy: 0.3339 - 163s/epoch - 889us/step\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 6.329092502593994 - Accuracy: 33.533257246017456%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 6.561932563781738 - Accuracy: 33.15962851047516%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 6.159642219543457 - Accuracy: 32.92856812477112%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 6.348387718200684 - Accuracy: 33.60373675823212%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 6.31456995010376 - Accuracy: 33.26942026615143%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6 - Loss: 6.321241855621338 - Accuracy: 33.559489250183105%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7 - Loss: 6.242488861083984 - Accuracy: 33.46607685089111%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8 - Loss: 6.445072650909424 - Accuracy: 33.66765081882477%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9 - Loss: 6.473275184631348 - Accuracy: 33.33333432674408%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 6.310897350311279 - Accuracy: 33.39233100414276%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 33.39134931564331 (+- 0.2148344495597065)\n",
      "> Loss: 6.350660085678101\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cols = [\"StationEnd\", \"Count\", \"Count1\", \"Count1week\", \"Temp\", \"ATemp\", \"Year\", \"Humidity\", \"Hour\"]\n",
    "\n",
    "met1 = dataset[[col for col in dataset.columns if col in cols]]\n",
    "\n",
    "X = met1.drop(columns=[\"Count\"])\n",
    "y = met1[\"Count\"]\n",
    "\n",
    "X = np.reshape(X.values, (X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "model_met1 = Sequential()\n",
    "model_met1.add(LSTM(4, input_shape=(1,met1.shape[1]-1)))\n",
    "model_met1.add(Dense(1))\n",
    "model_met1.compile(loss='mean_squared_error', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for train, test in kfold.split(X, y):\n",
    "    model_met1.fit(X[train], y[train], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model_met1.evaluate(X[test], y[test], verbose=0)\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "mean = np.mean(loss_per_fold)\n",
    "print(f'> Loss: {mean}')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "MSE.append(mean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 6\n",
    "Input: c(t), StationEnd, Temp, ATemp, Year, Humidity, Hour, WeatherSituation\n",
    "\n",
    "Output: c(t+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 09:11:15.570186: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 09:11:15.571321: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 09:11:15.572016: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-11 09:11:15.786683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 09:11:15.787872: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 09:11:15.788680: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-11 09:11:16.126081: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 09:11:16.127438: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 09:11:16.128149: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m# K-fold Cross Validation model evaluation\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m kfold\u001b[39m.\u001b[39msplit(X, y):\n\u001b[0;32m---> 23\u001b[0m     model_met1\u001b[39m.\u001b[39;49mfit(X[train], y[train], epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m     25\u001b[0m     \u001b[39m# Generate generalization metrics\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     scores \u001b[39m=\u001b[39m model_met1\u001b[39m.\u001b[39mevaluate(X[test], y[test], verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/BikeSharingDeepLearning/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/BikeSharingDeepLearning/venv/lib/python3.8/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Desktop/BikeSharingDeepLearning/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/BikeSharingDeepLearning/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/BikeSharingDeepLearning/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Desktop/BikeSharingDeepLearning/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:144\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m    143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[0;32m--> 144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Desktop/BikeSharingDeepLearning/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1961\u001b[0m, in \u001b[0;36mConcreteFunction.captured_inputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1955\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m   1956\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcaptured_inputs\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1957\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns external Tensors captured by this function.\u001b[39;00m\n\u001b[1;32m   1958\u001b[0m \n\u001b[1;32m   1959\u001b[0m \u001b[39m  self.__call__(*args) passes `args + self.captured_inputs` to the function.\u001b[39;00m\n\u001b[1;32m   1960\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1961\u001b[0m   \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39;49mflatten(\n\u001b[1;32m   1962\u001b[0m       [x() \u001b[39mif\u001b[39;49;00m \u001b[39mcallable\u001b[39;49m(x) \u001b[39melse\u001b[39;49;00m x \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_captured_inputs],\n\u001b[1;32m   1963\u001b[0m       expand_composites\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Desktop/BikeSharingDeepLearning/venv/lib/python3.8/site-packages/tensorflow/python/util/nest.py:454\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[39mreturn\u001b[39;00m [\u001b[39mNone\u001b[39;00m]\n\u001b[1;32m    453\u001b[0m expand_composites \u001b[39m=\u001b[39m \u001b[39mbool\u001b[39m(expand_composites)\n\u001b[0;32m--> 454\u001b[0m \u001b[39mreturn\u001b[39;00m _pywrap_utils\u001b[39m.\u001b[39;49mFlatten(structure, expand_composites)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cols = [\"StationEnd\", \"Count\", \"Count1\", \"Count1week\", \"Temp\", \"ATemp\", \"Year\", \"Humidity\", \"Hour\", \"WeatherSituation\"]\n",
    "\n",
    "met1 = dataset[[col for col in dataset.columns if col in cols]]\n",
    "\n",
    "X = met1.drop(columns=[\"Count\"])\n",
    "y = met1[\"Count\"]\n",
    "\n",
    "X = np.reshape(X.values, (X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "model_met1 = Sequential()\n",
    "model_met1.add(LSTM(4, input_shape=(1,met1.shape[1]-1)))\n",
    "model_met1.add(Dense(1))\n",
    "model_met1.compile(loss='mean_squared_error', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for train, test in kfold.split(X, y):\n",
    "    model_met1.fit(X[train], y[train], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model_met1.evaluate(X[test], y[test], verbose=0)\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "mean = np.mean(loss_per_fold)\n",
    "print(f'> Loss: {mean}')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "MSE.append(mean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 7\n",
    "Input: c(t), StationEnd, Temp, ATemp, Humidity\n",
    "\n",
    "Output: c(t+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 09:13:25.730532: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 09:13:25.731629: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 09:13:25.732264: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-11 09:13:25.900942: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 09:13:25.901885: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 09:13:25.902565: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-11 09:13:26.201653: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 09:13:26.202625: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 09:13:26.203544: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183062/183062 - 158s - loss: 4.2817 - accuracy: 0.3341 - 158s/epoch - 862us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 09:16:03.763978: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 09:16:03.765031: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 09:16:03.765668: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183062/183062 - 157s - loss: 4.1542 - accuracy: 0.3336 - 157s/epoch - 856us/step\n",
      "183062/183062 - 156s - loss: 4.1551 - accuracy: 0.3337 - 156s/epoch - 850us/step\n",
      "183063/183063 - 157s - loss: 4.1274 - accuracy: 0.3338 - 157s/epoch - 860us/step\n",
      "183063/183063 - 158s - loss: 4.1363 - accuracy: 0.3338 - 158s/epoch - 861us/step\n",
      "183063/183063 - 157s - loss: 4.1157 - accuracy: 0.3338 - 157s/epoch - 859us/step\n",
      "183063/183063 - 158s - loss: 4.1133 - accuracy: 0.3341 - 158s/epoch - 862us/step\n",
      "183063/183063 - 156s - loss: 4.1156 - accuracy: 0.3341 - 156s/epoch - 851us/step\n",
      "183063/183063 - 156s - loss: 4.1165 - accuracy: 0.3343 - 156s/epoch - 855us/step\n",
      "183063/183063 - 154s - loss: 4.1157 - accuracy: 0.3336 - 154s/epoch - 843us/step\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 4.084145545959473 - Accuracy: 33.17437767982483%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 4.133046627044678 - Accuracy: 33.65616202354431%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 4.042393684387207 - Accuracy: 33.54800641536713%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 4.108292102813721 - Accuracy: 33.46607685089111%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 4.1442108154296875 - Accuracy: 33.480826020240784%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6 - Loss: 4.169504165649414 - Accuracy: 33.461159467697144%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7 - Loss: 4.206108570098877 - Accuracy: 33.23992192745209%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8 - Loss: 4.173095226287842 - Accuracy: 33.21042358875275%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9 - Loss: 4.139368534088135 - Accuracy: 32.99901783466339%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 4.175709247589111 - Accuracy: 33.67748260498047%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 33.3913454413414 (+- 0.2125248863213651)\n",
      "> Loss: 4.137587451934815\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cols = [\"StationEnd\", \"Count\", \"Count1\", \"Count1week\", \"Temp\", \"ATemp\", \"Humidity\"]\n",
    "\n",
    "met1 = dataset[[col for col in dataset.columns if col in cols]]\n",
    "\n",
    "X = met1.drop(columns=[\"Count\"])\n",
    "y = met1[\"Count\"]\n",
    "\n",
    "X = np.reshape(X.values, (X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "model_met1 = Sequential()\n",
    "model_met1.add(LSTM(4, input_shape=(1,met1.shape[1]-1)))\n",
    "model_met1.add(Dense(1))\n",
    "model_met1.compile(loss='mean_squared_error', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for train, test in kfold.split(X, y):\n",
    "    model_met1.fit(X[train], y[train], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model_met1.evaluate(X[test], y[test], verbose=0)\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "mean = np.mean(loss_per_fold)\n",
    "print(f'> Loss: {mean}')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "MSE.append(mean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 8\n",
    "Input: c(t), StationEnd, Temp, ATemp, Humidity, Hour\n",
    "\n",
    "Output: c(t+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 09:39:37.219065: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 09:39:37.220304: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 09:39:37.221036: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-11 09:39:37.382289: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 09:39:37.383060: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 09:39:37.383777: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-11 09:39:37.686429: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 09:39:37.687871: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 09:39:37.688608: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183062/183062 - 151s - loss: 4.2238 - accuracy: 0.3337 - 151s/epoch - 825us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 09:42:08.482138: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 09:42:08.483225: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 09:42:08.483895: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183062/183062 - 150s - loss: 4.0487 - accuracy: 0.3337 - 150s/epoch - 817us/step\n",
      "183062/183062 - 151s - loss: 4.0007 - accuracy: 0.3332 - 151s/epoch - 825us/step\n",
      "183063/183063 - 151s - loss: 3.9606 - accuracy: 0.3338 - 151s/epoch - 826us/step\n",
      "183063/183063 - 150s - loss: 3.9486 - accuracy: 0.3339 - 150s/epoch - 820us/step\n",
      "183063/183063 - 153s - loss: 3.9240 - accuracy: 0.3335 - 153s/epoch - 834us/step\n",
      "183063/183063 - 151s - loss: 3.9156 - accuracy: 0.3336 - 151s/epoch - 827us/step\n",
      "183063/183063 - 151s - loss: 3.9087 - accuracy: 0.3339 - 151s/epoch - 823us/step\n",
      "183063/183063 - 153s - loss: 3.8993 - accuracy: 0.3336 - 153s/epoch - 833us/step\n",
      "183063/183063 - 150s - loss: 3.8948 - accuracy: 0.3338 - 150s/epoch - 819us/step\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 4.10745906829834 - Accuracy: 33.4103524684906%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 3.9675774574279785 - Accuracy: 33.23337137699127%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 3.9736380577087402 - Accuracy: 33.83806049823761%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 3.9733941555023193 - Accuracy: 33.4316611289978%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 3.8457698822021484 - Accuracy: 33.21042358875275%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6 - Loss: 3.8618009090423584 - Accuracy: 33.534905314445496%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7 - Loss: 3.8632194995880127 - Accuracy: 33.39233100414276%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8 - Loss: 3.8924121856689453 - Accuracy: 33.121928572654724%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9 - Loss: 3.906735897064209 - Accuracy: 33.4316611289978%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 3.847496747970581 - Accuracy: 33.20550620555878%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 33.38102012872696 (+- 0.196855479633081)\n",
      "> Loss: 3.9239503860473635\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cols = [\"StationEnd\", \"Count\", \"Count1\", \"Count1week\", \"Temp\", \"ATemp\", \"Humidity\", \"Hour\"]\n",
    "\n",
    "met1 = dataset[[col for col in dataset.columns if col in cols]]\n",
    "\n",
    "X = met1.drop(columns=[\"Count\"])\n",
    "y = met1[\"Count\"]\n",
    "\n",
    "X = np.reshape(X.values, (X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "model_met1 = Sequential()\n",
    "model_met1.add(LSTM(4, input_shape=(1,met1.shape[1]-1)))\n",
    "model_met1.add(Dense(1))\n",
    "model_met1.compile(loss='mean_squared_error', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for train, test in kfold.split(X, y):\n",
    "    model_met1.fit(X[train], y[train], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model_met1.evaluate(X[test], y[test], verbose=0)\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "mean = np.mean(loss_per_fold)\n",
    "print(f'> Loss: {mean}')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "MSE.append(mean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 9\n",
    "Input: c(t), StationEnd, Temp, ATemp, Humidity, Hour, WeatherSituation\n",
    "\n",
    "Output: c(t+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 10:04:51.713032: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 10:04:51.714223: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 10:04:51.714901: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-11 10:04:51.879938: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 10:04:51.880721: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 10:04:51.881430: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-11 10:04:52.158786: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 10:04:52.159879: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 10:04:52.160556: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183062/183062 - 152s - loss: 4.2057 - accuracy: 0.3334 - 152s/epoch - 832us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 10:07:24.282186: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 10:07:24.282995: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 10:07:24.283848: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183062/183062 - 150s - loss: 4.0808 - accuracy: 0.3341 - 150s/epoch - 821us/step\n",
      "183062/183062 - 153s - loss: 4.0418 - accuracy: 0.3335 - 153s/epoch - 834us/step\n",
      "183063/183063 - 151s - loss: 4.0193 - accuracy: 0.3343 - 151s/epoch - 823us/step\n",
      "183063/183063 - 151s - loss: 3.9846 - accuracy: 0.3336 - 151s/epoch - 824us/step\n",
      "183063/183063 - 151s - loss: 3.9562 - accuracy: 0.3333 - 151s/epoch - 823us/step\n",
      "183063/183063 - 154s - loss: 3.9251 - accuracy: 0.3340 - 154s/epoch - 839us/step\n",
      "183063/183063 - 155s - loss: 3.9155 - accuracy: 0.3335 - 155s/epoch - 847us/step\n",
      "183063/183063 - 156s - loss: 3.8911 - accuracy: 0.3333 - 156s/epoch - 851us/step\n",
      "183063/183063 - 155s - loss: 3.8969 - accuracy: 0.3331 - 155s/epoch - 849us/step\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 4.148143768310547 - Accuracy: 33.44968259334564%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 4.0007452964782715 - Accuracy: 33.076053857803345%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 4.072449684143066 - Accuracy: 33.67582857608795%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 4.016265869140625 - Accuracy: 32.94985294342041%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 3.9830994606018066 - Accuracy: 33.45132768154144%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6 - Loss: 3.805821657180786 - Accuracy: 33.62340331077576%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7 - Loss: 3.92087721824646 - Accuracy: 32.99901783466339%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8 - Loss: 3.9599449634552 - Accuracy: 33.41691195964813%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9 - Loss: 4.047276496887207 - Accuracy: 33.41691195964813%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 3.828754425048828 - Accuracy: 33.67748260498047%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 33.37364733219147 (+- 0.2588585521002546)\n",
      "> Loss: 3.97833788394928\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cols = [\"StationEnd\", \"Count\", \"Count1\", \"Count1week\", \"Temp\", \"ATemp\", \"Humidity\", \"Hour\", \"WeatherSituation\"]\n",
    "\n",
    "met1 = dataset[[col for col in dataset.columns if col in cols]]\n",
    "\n",
    "X = met1.drop(columns=[\"Count\"])\n",
    "y = met1[\"Count\"]\n",
    "\n",
    "X = np.reshape(X.values, (X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "model_met1 = Sequential()\n",
    "model_met1.add(LSTM(4, input_shape=(1,met1.shape[1]-1)))\n",
    "model_met1.add(Dense(1))\n",
    "model_met1.compile(loss='mean_squared_error', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for train, test in kfold.split(X, y):\n",
    "    model_met1.fit(X[train], y[train], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model_met1.evaluate(X[test], y[test], verbose=0)\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "mean = np.mean(loss_per_fold)\n",
    "print(f'> Loss: {mean}')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "MSE.append(mean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 10\n",
    "Input: c(t), StationEnd, Temp, Humidity, Hour, WeatherSituation\n",
    "\n",
    "Output: c(t+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 11:20:24.450963: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 11:20:24.452497: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 11:20:24.453363: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-11 11:20:24.656238: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 11:20:24.658606: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 11:20:24.659502: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-11 11:20:24.979667: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 11:20:24.981002: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 11:20:24.981762: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183062/183062 - 162s - loss: 4.2448 - accuracy: 0.3339 - 162s/epoch - 882us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 11:23:06.195253: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-11 11:23:06.196536: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-11 11:23:06.197269: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183062/183062 - 161s - loss: 4.0862 - accuracy: 0.3343 - 161s/epoch - 878us/step\n",
      "183062/183062 - 160s - loss: 4.0476 - accuracy: 0.3336 - 160s/epoch - 874us/step\n",
      "183063/183063 - 158s - loss: 4.0234 - accuracy: 0.3337 - 158s/epoch - 864us/step\n",
      "183063/183063 - 161s - loss: 4.0240 - accuracy: 0.3341 - 161s/epoch - 879us/step\n",
      "183063/183063 - 161s - loss: 4.0346 - accuracy: 0.3330 - 161s/epoch - 878us/step\n",
      "183063/183063 - 160s - loss: 4.0188 - accuracy: 0.3336 - 160s/epoch - 872us/step\n",
      "183063/183063 - 160s - loss: 4.0001 - accuracy: 0.3335 - 160s/epoch - 873us/step\n",
      "183063/183063 - 160s - loss: 4.0139 - accuracy: 0.3338 - 160s/epoch - 872us/step\n",
      "183063/183063 - 161s - loss: 3.9995 - accuracy: 0.3340 - 161s/epoch - 879us/step\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 4.1289262771606445 - Accuracy: 32.879406213760376%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 3.929508924484253 - Accuracy: 32.95806646347046%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 4.413745403289795 - Accuracy: 33.528342843055725%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 4.006124019622803 - Accuracy: 33.44641029834747%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 3.986171007156372 - Accuracy: 33.0530971288681%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6 - Loss: 3.817964792251587 - Accuracy: 34.12487804889679%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7 - Loss: 3.9136526584625244 - Accuracy: 33.564403653144836%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8 - Loss: 4.158286094665527 - Accuracy: 33.64798426628113%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9 - Loss: 3.9205334186553955 - Accuracy: 33.40216279029846%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 4.04398775100708 - Accuracy: 33.22025537490845%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 33.38250070810318 (+- 0.3533431820683323)\n",
      "> Loss: 4.031890034675598\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cols = [\"StationEnd\", \"Count\", \"Count1\", \"Count1week\", \"Temp\", \"Humidity\", \"Hour\"]\n",
    "\n",
    "met1 = dataset[[col for col in dataset.columns if col in cols]]\n",
    "\n",
    "X = met1.drop(columns=[\"Count\"])\n",
    "y = met1[\"Count\"]\n",
    "\n",
    "X = np.reshape(X.values, (X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "model_met1 = Sequential()\n",
    "model_met1.add(LSTM(4, input_shape=(1,met1.shape[1]-1)))\n",
    "model_met1.add(Dense(1))\n",
    "model_met1.compile(loss='mean_squared_error', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for train, test in kfold.split(X, y):\n",
    "    model_met1.fit(X[train], y[train], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model_met1.evaluate(X[test], y[test], verbose=0)\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "mean = np.mean(loss_per_fold)\n",
    "print(f'> Loss: {mean}')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "MSE.append(mean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Methods')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(1,len(MSE)+1)), MSE, marker=\"o\")\n",
    "plt.title(\"Mean Squared Error by method\")\n",
    "plt.xlabel(\"Methods\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
